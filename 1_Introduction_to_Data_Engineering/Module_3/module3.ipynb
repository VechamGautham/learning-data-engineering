{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a98483f",
   "metadata": {},
   "source": [
    "# 📚 Index\n",
    "\n",
    "- [Enterprise Architecture](#enterprise-architecture)\n",
    "\n",
    "- [Conway’s Law](#conways-law)\n",
    "\n",
    "- [Principles of Good Data Architecture](#principles-of-good-data-architecture)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe58e9f",
   "metadata": {},
   "source": [
    "# Enterprise Architecture\n",
    "\n",
    "Enterprise Architecture is the design of systems to support **change** in an enterprise — achieved by **flexible and reversible decisions** through careful evaluation of trade-offs.\n",
    "\n",
    "It consists of **4 core components**:\n",
    "\n",
    "![Enterprise Architecture Diagram](./images/enterprice_architecture.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 🧩 Business Architecture  \n",
    "**Purpose:** Defines the **product or service strategy** and **business model** of the enterprise.\n",
    "\n",
    "**Example:**  \n",
    "An e-commerce company wants:\n",
    "- 1-day delivery\n",
    "- Personalized product recommendations\n",
    "- Expansion to new regions\n",
    "\n",
    "**Data Engineer's Role:**  \n",
    "You need to understand these goals and build pipelines to track:\n",
    "- Order delivery times  \n",
    "- Customer behavior  \n",
    "- Sales by region\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 🏗 Application Architecture  \n",
    "**Purpose:** Describes the **structure and interaction** of key applications that serve business needs.\n",
    "\n",
    "**Example:**  \n",
    "Flipkart might use:\n",
    "- Login Service  \n",
    "- Product Catalog  \n",
    "- Recommendation Engine  \n",
    "- Order Management  \n",
    "\n",
    "**Data Engineer's Role:**  \n",
    "You extract data via:\n",
    "- APIs  \n",
    "- Event streams (Kafka)  \n",
    "- Database snapshots  \n",
    "\n",
    "Then push it into the warehouse/lake for analytics.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 🖥 Technical Architecture  \n",
    "**Purpose:** Defines the **software and hardware** infrastructure (cloud, compute, network, tools).\n",
    "\n",
    "**Example:**  \n",
    "- AWS EC2 for compute  \n",
    "- S3 for storage  \n",
    "- Glue & Spark for processing  \n",
    "- Airflow for orchestration  \n",
    "- Terraform for IaC  \n",
    "\n",
    "**Data Engineer's Role:**  \n",
    "You build and deploy using:\n",
    "- Scalable, secure, cost-effective cloud resources  \n",
    "- Tools like Terraform to manage infrastructure as code  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. 🗃 Data Architecture  \n",
    "**Purpose:** Supports the **evolving data needs** of the organization.\n",
    "\n",
    "**Example Workflow:**\n",
    "- Extract from MySQL (RDS)  \n",
    "- Transform via Glue into a star schema  \n",
    "- Store in S3 as Parquet  \n",
    "- Query via Athena  \n",
    "- Visualize via Jupyter or QuickSight  \n",
    "\n",
    "**Data Engineer's Role:**  \n",
    "Own the end-to-end data pipeline: from ingestion → transformation → serving.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 Why It Matters to You as a Data Engineer\n",
    "\n",
    "- Your pipelines must **support changing business needs**\n",
    "- You must make **reversible choices** when possible (2-way doors)\n",
    "- You contribute not just to the tech, but to **how the organization runs**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf7b3c5",
   "metadata": {},
   "source": [
    "## Conway’s Law\n",
    "\n",
    "> **\"Any organization that designs a system will produce a design whose structure is a copy of the organization’s communication structure.\"**  \n",
    "> — Melvin Conway\n",
    "\n",
    "### 🔍 What It Means\n",
    "\n",
    "Conway's Law suggests that the way teams **communicate and organize internally** will directly influence the **structure of the systems** they build.\n",
    "\n",
    "For example, if your company has separate departments that rarely collaborate (like Sales, Marketing, Finance, and Operations), each team may create their own isolated data systems — leading to **siloed architectures**.\n",
    "\n",
    "📉 **Siloed Teams = Siloed Systems**\n",
    "\n",
    "![Siloed Systems](./images/conway_law_1.png)\n",
    "\n",
    "But if the same departments work in a **collaborative, cross-functional** way — communicating frequently — the systems they build will be **more integrated and unified**.\n",
    "\n",
    "📈 **Collaborative Teams = Unified Architecture**\n",
    "\n",
    "![Unified System](./images/conway_law_2.png)\n",
    "\n",
    "### 🧑‍💻 Why It Matters to You as a Data Engineer\n",
    "\n",
    "Before designing a data architecture, **understand how your company communicates**:\n",
    "- Are teams siloed or cross-functional?\n",
    "- Do they share common goals or work in isolation?\n",
    "\n",
    "Even if your architecture looks perfect on paper, if it **clashes with your org's communication structure**, it’s likely to fail in practice.\n",
    "\n",
    "> ✅ Good data architecture reflects how people in the company work together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ca9ef9",
   "metadata": {},
   "source": [
    "## Principles of Good Data Architecture\n",
    "\n",
    "![Principles of Good Data Architecture](./images/principles_data_archi.png)\n",
    "\n",
    "Data architecture is not just about tools — it's about making smart, flexible, and impactful decisions that evolve with the organization.\n",
    "\n",
    "### 🔹 Theme 1: How Architecture Affects Others\n",
    "- **Choose common components wisely**  \n",
    "  Use tools that benefit multiple teams (e.g., Git, S3, Spark).\n",
    "- **Architecture is leadership**  \n",
    "  Architects lead by enabling others, mentoring, and setting standards.\n",
    "\n",
    "### 🔹 Theme 2: Architecture Is an Ongoing Process\n",
    "- **Always be architecting**  \n",
    "  Keep improving as needs change.\n",
    "- **Build loosely coupled systems**  \n",
    "  Make systems modular for flexibility.\n",
    "- **Make reversible decisions**  \n",
    "  Favor decisions you can back out of (e.g., changing storage classes).\n",
    "\n",
    "### 🔹 Theme 3: Unspoken But Understood Priorities\n",
    "- **Plan for failure**  \n",
    "  Assume systems will break — design for recovery.\n",
    "- **Architect for scalability**  \n",
    "  Plan ahead for data/user growth.\n",
    "- **Prioritize security**  \n",
    "  Build in data protection from day one.\n",
    "- **Embrace FinOps**  \n",
    "  Design systems with cost efficiency in mind.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔗 Common Components\n",
    "\n",
    "![Common Components](./images/common_components.png)\n",
    "\n",
    "Common components are tools and platforms shared across teams to increase efficiency and reduce duplication.\n",
    "\n",
    "### 🔧 Examples of Common Components\n",
    "- **Object Storage** – like Amazon S3, shared by all teams  \n",
    "- **Version Control Systems** – like Git for code collaboration  \n",
    "- **Monitoring & Observability** – systems to track health/performance  \n",
    "- **Processing Engines** – e.g., Spark, for distributed data processing\n",
    "\n",
    "Choosing common components well promotes collaboration, avoids silos, and reduces maintenance overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d70786",
   "metadata": {},
   "source": [
    "# Plan for Failure\n",
    "\n",
    "One of the key responsibilities of a data engineer is to **anticipate system failure** and design resilient, secure, and scalable architectures that minimize its impact. This principle is broken down into the following components:\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Availability\n",
    "\n",
    "> **Definition**: The percentage of time an IT service or component is expected to be in an operable state.\n",
    "\n",
    "Availability ensures users can access the system when needed. For example:\n",
    "\n",
    "- **Amazon S3 One Zone-IA**: 99.5% (≈ 44 hours downtime/year)\n",
    "- **Amazon S3 Standard**: 99.99% (≈ 1 hour downtime/year)\n",
    "\n",
    "![Availability](./images/plf_availability.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Reliability\n",
    "\n",
    "> **Definition**: The probability of a service or component performing its intended function within a specific time interval.\n",
    "\n",
    "Reliable systems operate predictably and meet defined performance standards, ensuring smooth user experience.\n",
    "\n",
    "![Reliability](./images/plf_reliability.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Durability\n",
    "\n",
    "> **Definition**: The ability of a system to **withstand data loss** from hardware failures, software bugs, or natural disasters.\n",
    "\n",
    "Durability ensures data is not lost. For instance, **Amazon S3** offers 99.999999999% durability — also called **11 nines**.\n",
    "\n",
    "![Durability](./images/plf_durability.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 🔐 Prioritize Security\n",
    "\n",
    "Security is critical to prevent breaches and ensure that failures do not lead to data loss or corruption.\n",
    "\n",
    "**Best Practices:**\n",
    "\n",
    "- 🛡️ Build a **Culture of Security**\n",
    "- 🔑 Apply **Principle of Least Privilege**\n",
    "- 🚫 Adopt **Zero-Trust Security** (no implicit trust, every action must be authenticated)\n",
    "\n",
    "![Security](./images/prioritize_security.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Recovery Objectives\n",
    "\n",
    "Understanding **how quickly** and **how much data** can be recovered helps mitigate risks during failures.\n",
    "\n",
    "- **RTO (Recovery Time Objective)**: Max acceptable outage time.\n",
    "- **RPO (Recovery Point Objective)**: Max acceptable data loss after recovery.\n",
    "\n",
    "These guide architectural decisions such as storage class or backup frequency.\n",
    "\n",
    "![RTO and RPO](./images/rto_rpo.png)\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Architect for Scalability & 💰 Embrace FinOps\n",
    "\n",
    "Anticipating load spikes or failures also means building systems that can scale cost-effectively.\n",
    "\n",
    "### Risks:\n",
    "- 🔺 Unforeseen high cloud costs\n",
    "- 🔻 Lost revenue due to system crashes during peak demand\n",
    "\n",
    "**Recommendations:**\n",
    "- Use **on-demand vs spot instances** wisely\n",
    "- Optimize for **cost and performance**\n",
    "- Build elastic systems that **scale up or down as needed**\n",
    "\n",
    "![Scalability and FinOps](./images/archi_for_scalability.png)\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Summary\n",
    "\n",
    "A good data engineer doesn’t just build systems that work under ideal conditions — they build systems that:\n",
    "\n",
    "- Remain **available** and **reliable** under stress  \n",
    "- **Protect data** from loss and corruption  \n",
    "- Are **secure** by design  \n",
    "- Are **cost-effective** and **scalable**  \n",
    "- Are built with **failure recovery** in mind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a32b6",
   "metadata": {},
   "source": [
    "## 🧱 Batch Data Architectures: ETL vs ELT\n",
    "\n",
    "Batch data architectures process data in **fixed intervals (batches)** rather than in real-time. Two popular patterns are:\n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 ETL – Extract, Transform, Load\n",
    "\n",
    "ETL is the **traditional data pipeline** used when real-time analysis isn't required.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. **Extract** data from source systems (databases, files, APIs).\n",
    "2. **Transform** data in a staging area (cleaning, aggregating, standardizing).\n",
    "3. **Load** transformed data into a data warehouse.\n",
    "\n",
    "![ETL](./images/etl.png)\n",
    "\n",
    "**✅ When to use ETL:**\n",
    "- Your transformations are **complex** or require **external processing tools**.\n",
    "- You want **control over data quality** before loading.\n",
    "- You’re working with **smaller volumes** of data.\n",
    "- You’re using legacy or on-premise systems.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 ELT – Extract, Load, Transform\n",
    "\n",
    "ELT is a **modern pattern** made possible by the power of cloud data warehouses (e.g., BigQuery, Snowflake).\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. **Extract** data from sources.\n",
    "2. **Load** raw data directly into the data warehouse.\n",
    "3. **Transform** inside the warehouse using SQL or built-in tools.\n",
    "\n",
    "![ELT](./images/elt.png)\n",
    "\n",
    "**✅ When to use ELT:**\n",
    "- Your data warehouse supports **high-performance computation**.\n",
    "- You’re dealing with **large-scale data** (big data).\n",
    "- You want to **defer transformation** to be more flexible for analysis.\n",
    "- You prefer a **schema-on-read** approach (raw data first, model later).\n",
    "\n",
    "---\n",
    "\n",
    "### ⚖️ Trade-offs Between ETL and ELT\n",
    "\n",
    "| Criteria         | ETL                                | ELT                                |\n",
    "|------------------|-------------------------------------|-------------------------------------|\n",
    "| **Flexibility**  | Less flexible (schema-on-write)     | More flexible (schema-on-read)      |\n",
    "| **Speed**        | Slower (transformation before load) | Faster ingestion                    |\n",
    "| **Complexity**   | Complex transformations outside DB  | Simplified using SQL in warehouse   |\n",
    "| **Use Case**     | Legacy systems, strict governance   | Modern cloud data platforms         |\n",
    "| **Cost**         | May require external tools          | Optimized using warehouse compute   |\n",
    "\n",
    "---\n",
    "\n",
    "**In summary**:  \n",
    "- Use **ETL** when you need control over transformation before data reaches your warehouse.  \n",
    "- Use **ELT** to **leverage warehouse power** and increase flexibility in modeling and analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7c9202",
   "metadata": {},
   "source": [
    "# ⛓️ Lambda, ⚡ Kappa, and 🔁 Unified Architectures in Data Engineering\n",
    "\n",
    "## ⚙️ Streaming Frameworks\n",
    "\n",
    "Before diving into the architectures, it's important to know the tools that enable real-time data processing:\n",
    "\n",
    "![Streaming Frameworks](./images/streaming_frameworks.png)\n",
    "\n",
    "- **Apache Kafka**: A distributed event streaming platform that stores and transports events reliably at scale.\n",
    "- **Apache Storm**: A real-time computation system for processing unbounded streams of data.\n",
    "- **Apache Samza**: Works with Kafka to process event streams in near real time.\n",
    "\n",
    "---\n",
    "\n",
    "## ⛓️ Lambda Architecture\n",
    "\n",
    "![Lambda Architecture](./images/lambda_archi.png)\n",
    "\n",
    "### 💡 What It Is:\n",
    "Lambda uses **two parallel pipelines** — one for batch, one for streaming — to handle both historical and real-time data.\n",
    "\n",
    "### 🔄 How It Works:\n",
    "- **Batch Layer**:\n",
    "  - Processes historical data in large chunks.\n",
    "  - Uses a data warehouse (e.g., BigQuery, Redshift) for storage and querying.\n",
    "- **Speed (Streaming) Layer**:\n",
    "  - Handles real-time data from sources like Kafka.\n",
    "  - Stores output in a NoSQL database (e.g., Cassandra).\n",
    "- **Serving Layer**:\n",
    "  - Combines both outputs to deliver a **complete view** for dashboards or ML models.\n",
    "\n",
    "### ✅ Pros:\n",
    "- Supports both fresh (stream) and comprehensive (batch) data.\n",
    "- Can serve accurate analytics with mixed granularity.\n",
    "\n",
    "### ❌ Cons:\n",
    "- Requires maintaining **two separate pipelines**.\n",
    "- Duplicate logic and maintenance effort.\n",
    "- Possible inconsistency between batch and stream outputs.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚡ Kappa Architecture\n",
    "\n",
    "![Kappa Architecture](./images/kappa_archi.png)\n",
    "\n",
    "### 💡 What It Is:\n",
    "Kappa eliminates the batch pipeline and uses only **streaming**. It treats all data as events and enables reprocessing from historical streams.\n",
    "\n",
    "### 🔄 How It Works:\n",
    "- Data from **source systems** flows into a **stream processing engine** (e.g., Kafka Streams, Flink).\n",
    "- The processed data feeds into a **single serving layer** for querying and consumption.\n",
    "- **Historical replay**: Because Kafka can retain logs, older data can be reprocessed if logic changes.\n",
    "\n",
    "### ✅ Pros:\n",
    "- **Simpler** than Lambda — only one codebase to maintain.\n",
    "- Supports real-time and reprocessing use cases.\n",
    "\n",
    "### ❌ Cons:\n",
    "- Not great for very large historical aggregations.\n",
    "- Needs long-term stream retention if historical replays are required.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 Unified Batch & Streaming Architecture\n",
    "\n",
    "![Unified Architecture](./images/unified_batch_streaming.png)\n",
    "\n",
    "### 💡 What It Is:\n",
    "Unified architecture views **batch as a special case of streaming**. Uses a **single codebase** for both.\n",
    "\n",
    "### 🔄 How It Works:\n",
    "- Treats all data as events:\n",
    "  - Real-time data = **unbounded event streams**\n",
    "  - Batch = **bounded slices** of event streams (e.g., hourly/daily windows)\n",
    "- Stream processors (e.g., **Apache Beam**, **Apache Flink**, **Google Dataflow**) can apply the same transformations on both batch and streaming data.\n",
    "- Output goes to warehouses, dashboards, ML pipelines, etc.\n",
    "\n",
    "### ✅ Pros:\n",
    "- One codebase = less duplication, easier maintenance.\n",
    "- Flexible — adapts easily as batch or streaming.\n",
    "- Scalable and modern.\n",
    "\n",
    "### ❌ Cons:\n",
    "- Steeper learning curve.\n",
    "- Needs modern infrastructure and tools to implement correctly.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Summary\n",
    "\n",
    "| Feature            | Lambda                    | Kappa                    | Unified Batch & Streaming    |\n",
    "|--------------------|----------------------------|--------------------------|-------------------------------|\n",
    "| Pipelines          | Batch + Stream             | Stream only              | Single (unified)              |\n",
    "| Codebase           | Two                        | One                      | One                           |\n",
    "| Complexity         | High                       | Medium                   | Medium                        |\n",
    "| Historical Replay  | Yes (via batch)            | Yes (via stream replay)  | Yes (via event windowing)     |\n",
    "| Tools              | Kafka, Hadoop, Cassandra   | Kafka, Flink             | Beam, Flink, Dataflow         |\n",
    "\n",
    "---\n",
    "\n",
    "> ⚠️ Tip: In modern data engineering, **Unified** is the most preferred approach. But Kappa is a great real-time-first alternative when batch is not a priority. Lambda is more legacy but still seen in enterprises transitioning to real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5473e3a",
   "metadata": {},
   "source": [
    "## Server vs Container vs Serverless\n",
    "\n",
    "Hosting an application in the cloud usually means choosing between **servers**, **containers**, or **serverless** architectures. Each comes with different levels of responsibility and flexibility.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. **Server**\n",
    "\n",
    "You **manage everything**:  \n",
    "- You set up the server (like an EC2 instance)  \n",
    "- Install and update OS  \n",
    "- Manage packages  \n",
    "- Configure networking, security, scaling  \n",
    "\n",
    "🧱 **Think of it as a full virtual machine you control**.\n",
    "\n",
    "**Example:**  \n",
    "- AWS EC2  \n",
    "- You manually provision a VM, install your stack (Python, PostgreSQL, etc.), deploy code.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 2. **Container**\n",
    "\n",
    "You **package your application and dependencies** in a lightweight, portable box (a container).\n",
    "\n",
    "- The **host OS, networking, and scaling are handled** by infrastructure like Kubernetes.\n",
    "- You only worry about the app code and dependencies.\n",
    "\n",
    "**Example:**  \n",
    "- Docker container with your ML model  \n",
    "- Runs on GKE (Google Kubernetes Engine) or EKS (Amazon's Kubernetes)\n",
    "\n",
    "💡 Advantage: Faster deploys, portability  \n",
    "💡 Disadvantage: You still manage images, container orchestration\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 3. **Serverless**\n",
    "\n",
    "You **don't manage any server or container**. Just write your code and let the cloud run it:\n",
    "\n",
    "- Auto-scales  \n",
    "- Built-in fault-tolerance  \n",
    "- Pay only when code runs (event-driven)\n",
    "\n",
    "🧠 Think of it as a “function-as-a-service”.\n",
    "\n",
    "**Example:**  \n",
    "- AWS Lambda (run code when file is uploaded to S3)  \n",
    "- AWS Glue, Athena\n",
    "\n",
    "💡 **Best for:**  \n",
    "- Small, fast workloads like ETL triggers, alerts, chatbots  \n",
    "💡 **Not suitable for:**  \n",
    "- Long-running or complex workloads  \n",
    "- Use Kubernetes/containers in that case\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Summary Table\n",
    "\n",
    "| Architecture | What You Manage              | Best For                              | Example         |\n",
    "|--------------|------------------------------|----------------------------------------|------------------|\n",
    "| Server       | Everything (OS, networking)  | Full control, legacy systems          | AWS EC2          |\n",
    "| Container    | App + dependencies only      | Portable microservices, batch jobs    | Docker + EKS     |\n",
    "| Serverless   | Nothing (fully managed)      | Fast event-based code, automation     | AWS Lambda, Glue |\n",
    "\n",
    "---\n",
    "\n",
    "### 🖼️ Architecture Images\n",
    "\n",
    "#### Server, Container, Serverless\n",
    "![Server, Container, Serverless](./images/server_container_serverless.png)\n",
    "\n",
    "#### When to Use Serverless Services\n",
    "![When to Use Serverless](./images/serverless_services.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb487ac",
   "metadata": {},
   "source": [
    "# 📦 Three-Tier Architecture for Scalable Web Applications on AWS\n",
    "\n",
    "## 🧩 Overview\n",
    "\n",
    "To host any modern web application, we use a **three-tier architecture**:\n",
    "1. **Data Tier** – where data is stored\n",
    "2. **Logic Tier** – where business logic is executed\n",
    "3. **Presentation Tier** – where users interact with the app\n",
    "\n",
    "---\n",
    "<pre>\n",
    "## 📊 Architectural Diagram\n",
    "\n",
    "[ Client Device ]\n",
    "⬇️\n",
    "[ Presentation Tier ]\n",
    "⬇️\n",
    "[ Logic Tier (ALB + Auto Scaling EC2) ]\n",
    "⬇️\n",
    "[ Data Tier (S3 Bucket) ]\n",
    "</pre>\n",
    "---\n",
    "\n",
    "## 🔹 Step 1: Presentation Tier\n",
    "\n",
    "- This is what your end-users interact with – a **dashboard** or **web page**.\n",
    "- Hosted on EC2 instances behind a Load Balancer.\n",
    "- Pulls processed data from the logic tier and displays it in charts, tables, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Step 2: Logic Tier\n",
    "\n",
    "### 🔁 EC2 Auto Scaling Group\n",
    "- A group of **Amazon EC2 instances** running your application logic.\n",
    "- **Auto Scaling** ensures the number of instances grows or shrinks based on user demand.\n",
    "- Instances are placed in **multiple Availability Zones** for higher availability.\n",
    "\n",
    "### 🎯 Application Load Balancer (ALB)\n",
    "- Distributes incoming traffic across EC2 instances.\n",
    "- Ensures **no single instance is overwhelmed**.\n",
    "- Single point of entry for your web app.\n",
    "- You configure **ALB security groups** to control access.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Step 3: Data Tier\n",
    "\n",
    "- Data is stored in an **Amazon S3 bucket**.\n",
    "- Logic tier pulls data from S3 and processes it for use in dashboards or exports.\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 Step 4: Monitoring with CloudWatch\n",
    "\n",
    "- Use **Amazon CloudWatch** to monitor:\n",
    "  - EC2 **CPU usage**\n",
    "  - **Network traffic**\n",
    "  - **Request errors**\n",
    "- Triggers alerts or Auto Scaling actions when thresholds are reached.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔐 Step 5: Security\n",
    "\n",
    "- Use **Security Groups** to:\n",
    "  - Allow access only via **HTTP (port 80)** or **HTTPS (port 443)**.\n",
    "  - Restrict IP ranges or allow only internal access.\n",
    "- Protect EC2 and ALB from unauthorized traffic.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Key Benefits\n",
    "\n",
    "| Feature              | Benefit                                |\n",
    "|----------------------|-----------------------------------------|\n",
    "| Auto Scaling         | Grows with demand, saves costs          |\n",
    "| Load Balancer        | Balances traffic, improves performance  |\n",
    "| CloudWatch           | Real-time monitoring & alerting         |\n",
    "| S3 Storage           | Durable, scalable, cost-effective data  |\n",
    "| Security Groups      | Fine-grained access control             |\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 Final Notes\n",
    "\n",
    "This architecture follows **AWS Well-Architected Framework** principles:\n",
    "- **Operational Excellence**\n",
    "- **Security**\n",
    "- **Reliability**\n",
    "- **Performance Efficiency**\n",
    "- **Cost Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c337b8b",
   "metadata": {},
   "source": [
    "# Assignment 2: Web Application Architecture and Scaling with AWS\n",
    "\n",
    "## 📝 Objective\n",
    "\n",
    "In this assignment, your goal is to work with a web application hosted on **Amazon EC2**. The purpose of the application is to serve **dashboards** and **analytical data** to both internal and external users via the internet. You’ll focus on ensuring the system is:\n",
    "\n",
    "- Scalable\n",
    "- Reliable\n",
    "- Secure\n",
    "- Efficient\n",
    "\n",
    "You will achieve this by applying the **AWS Well-Architected Framework** and monitoring performance with **Amazon CloudWatch**.\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Use Case\n",
    "\n",
    "Your company has built a **data pipeline** to:\n",
    "1. Ingest data\n",
    "2. Transform data\n",
    "3. Serve data to internal data analysts\n",
    "\n",
    "Now, you’ve been tasked to:\n",
    "- Share **transformed data** with **external clients**\n",
    "- Serve this data through a **web application**\n",
    "- Ensure that this application can **scale**, is **secure**, and runs **efficiently**\n",
    "\n",
    "---\n",
    "\n",
    "## 🏗️ Architectural Diagram\n",
    "\n",
    "The system follows a **3-tier architecture**:\n",
    "\n",
    "1. **Data Tier** – Where data is stored (S3)\n",
    "2. **Logic Tier** – Where business logic is executed (EC2 + Auto Scaling)\n",
    "3. **Presentation Tier** – What the user sees (Dashboards)\n",
    "\n",
    "![Web App Architecture](./images/archi_diagram.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 📦 Components\n",
    "\n",
    "### 🔹 Data Tier\n",
    "- **Amazon S3** stores the raw and transformed data.\n",
    "- **Amazon Athena** is used to query this data using SQL-like syntax.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Logic Tier\n",
    "\n",
    "This layer handles **business logic** and **client requests**.\n",
    "\n",
    "![Logic Tier](./images/logic_tier.png)\n",
    "\n",
    "**Key Components**:\n",
    "- **Auto Scaling Group**: Manages EC2 instances based on demand.\n",
    "  - Starts with 2 EC2 instances.\n",
    "  - Launched in separate **Availability Zones** for reliability.\n",
    "  - Automatically scales up/down.\n",
    "- **Application Load Balancer (ALB)**:\n",
    "  - Distributes incoming traffic across instances.\n",
    "  - Acts as a **single point of entry** for client requests.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Presentation Tier\n",
    "- Consists of a **frontend interface** (webpage/dashboard).\n",
    "- Users access the system through their **devices**.\n",
    "- The frontend shows processed data fetched from the logic tier.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 What You'll Do in This Assignment\n",
    "\n",
    "- Simulate **client traffic** to the web application.\n",
    "- Monitor:\n",
    "  - CPU usage\n",
    "  - Memory utilization\n",
    "  - Network activity\n",
    "- Optimize:\n",
    "  - Auto Scaling rules\n",
    "  - Instance types\n",
    "  - Load balancer settings\n",
    "- Ensure:\n",
    "  - Application is highly available.\n",
    "  - Costs are optimized.\n",
    "  - Application is secure.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Tools You’ll Use\n",
    "\n",
    "- **Amazon EC2** – Compute resource\n",
    "- **Amazon ALB** – Load balancing\n",
    "- **Amazon CloudWatch** – Monitoring\n",
    "- **Amazon S3 & Athena** – Data tier\n",
    "- **Auto Scaling Group** – Elastic compute\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Goal\n",
    "\n",
    "Ensure that the application is:\n",
    "- Ready to handle real-time client requests\n",
    "- Scalable with user traffic\n",
    "- Resilient across availability zones\n",
    "- Optimized for performance and cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
