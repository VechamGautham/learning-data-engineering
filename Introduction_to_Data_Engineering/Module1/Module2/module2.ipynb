{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bce03ec",
   "metadata": {},
   "source": [
    "# 📦 Source Systems in Data Engineering\n",
    "\n",
    "In data engineering, the **first step** in the lifecycle is obtaining data from various **source systems**. These are the systems where raw data originates and flows into your pipeline for processing and analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 What Are Source Systems?\n",
    "\n",
    "Source systems are where your data comes from. As a **data engineer**, you don't typically own these systems — they are created and maintained by other teams like software developers, third-party vendors, or partner platforms.\n",
    "\n",
    "Your job is to build **pipelines** that consume data from these sources and deliver it to **downstream systems** like dashboards, machine learning models, or data warehouses.\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Common Types of Source Systems\n",
    "\n",
    "| Type             | Description                                                                 | Real-World Example                                 |\n",
    "|------------------|-----------------------------------------------------------------------------|----------------------------------------------------|\n",
    "| **Databases**     | Structured data organized into tables or documents                         | Sales transactions from an e-commerce app          |\n",
    "| **Files**         | Unstructured data like CSVs, MP3s, images                                   | Product catalog stored in `products.csv`           |\n",
    "| **APIs**          | On-demand data accessed over the web                                       | Twitter API providing trending hashtags            |\n",
    "| **IoT Devices**   | Real-time data streamed from connected devices                              | GPS trackers on delivery vehicles                  |\n",
    "| **Data Sharing Platforms** | External datasets provided by other organizations                | AWS Data Exchange sharing market research files    |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Why Understanding Source Systems Is Important\n",
    "\n",
    "- Source systems are **not in your control**.\n",
    "- They can **fail**, change format/schema, or update without notice.\n",
    "- If you rely on unstable source systems without planning, your downstream pipelines may **break** silently.\n",
    "\n",
    "> Example: A software team renames or deletes columns in their database without telling you. Your pipeline crashes because it expects columns that no longer exist.\n",
    "\n",
    "---\n",
    "\n",
    "## 🤝 Best Practices\n",
    "\n",
    "- **Collaborate** with the owners of source systems\n",
    "- Understand how the data is **generated and updated**\n",
    "- Know what can **change** — and when\n",
    "- Design pipelines to be **resilient** to schema or format changes\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Analogy\n",
    "\n",
    "> Imagine you're a chef (data engineer). Your ingredients (data) come from various suppliers (source systems). One day, a supplier changes packaging or skips delivery without notice — your kitchen operations (pipelines) are disrupted unless you're prepared and have good communication.\n",
    "\n",
    "---\n",
    "\n",
    "## 📷 Diagram: Source Systems → Downstream Systems\n",
    "\n",
    "![Source Systems Flow](./image/source_systems.png)\n",
    "\n",
    "In the diagram above:\n",
    "- The left side shows **data sources** like databases, files, APIs, IoT, and data sharing platforms.\n",
    "- These sources **deliver data** through pipelines.\n",
    "- The right side shows **downstream systems** that consume the processed data.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Summary\n",
    "\n",
    "- **Source systems** are external systems where your pipeline starts.\n",
    "- They include databases, APIs, files, IoT devices, and more.\n",
    "- As a data engineer, your success depends on **understanding, monitoring, and adapting** to these systems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b7de79",
   "metadata": {},
   "source": [
    "# 🔄 Data Ingestion in Data Engineering\n",
    "\n",
    "## 1. Source Systems\n",
    "\n",
    "In the first stage of the data engineering lifecycle, data originates from **source systems**. These are systems that generate or hold the raw data we want to work with.\n",
    "\n",
    "### Common Source Systems:\n",
    "\n",
    "- **Databases** (e.g., sales or customer databases)\n",
    "- **Files** (CSV, JSON, audio, video)\n",
    "- **APIs** (e.g., Twitter API, product data API)\n",
    "- **IoT Devices** (e.g., GPS trackers, sensors)\n",
    "- **Data Sharing Platforms** (e.g., internal dashboards, 3rd-party datasets)\n",
    "\n",
    "These systems may be maintained by:\n",
    "- Other internal teams (e.g., backend engineers)\n",
    "- External vendors\n",
    "- Partner organizations\n",
    "\n",
    "As a data engineer, you don’t control these systems—but your pipelines depend on their structure and consistency.\n",
    "\n",
    "> 🔄 *Analogy:* Think of source systems as different taps (faucets) from which water (data) flows into a treatment plant (your data pipeline). You don’t control how the taps are built, but you must design your plant to handle the water reliably.\n",
    "\n",
    "### 📌 Image: Source Systems Diagram\n",
    "\n",
    "![Source Systems](./images/source_systems.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Frequency of Ingestion\n",
    "\n",
    "Once the data source is identified, you need to decide how **frequently** data should be ingested from it:\n",
    "\n",
    "- **Batch Ingestion**: Collect and move large chunks of data periodically (e.g., every hour/day).\n",
    "- **Streaming Ingestion**: Capture and process events/data in near real-time.\n",
    "\n",
    "> 💡 *Example:*  \n",
    "> - Batch: Moving website logs daily into a warehouse for weekly analysis.  \n",
    "> - Stream: Capturing user clicks in real-time to recommend products instantly.\n",
    "\n",
    "> 📦 *Analogy:*  \n",
    "> - **Batch**: Like collecting mail once a day from a mailbox.  \n",
    "> - **Streaming**: Like receiving WhatsApp messages instantly as they come in.\n",
    "\n",
    "### 📌 Image: Frequency of Ingestion\n",
    "\n",
    "![Frequency of Ingestion](./image/ingestion_frequency.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Batch Ingestion\n",
    "\n",
    "**Batch ingestion** means pulling data in chunks at scheduled times or after a set data size.\n",
    "\n",
    "- Often used in analytics and model training\n",
    "- Simple and resource-efficient\n",
    "- Great when real-time updates are not critical\n",
    "\n",
    "> 🕒 Example: Pulling transaction records from a POS (Point of Sale) system every night at 2 AM for analysis.\n",
    "\n",
    "### 📌 Image: Batch Ingestion\n",
    "\n",
    "![Batch Ingestion](./image/batch_ingestion.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Streaming and Batch Together\n",
    "\n",
    "Most real-world systems use a combination of batch and streaming ingestion.\n",
    "\n",
    "- **Batch Use Case**: Train ML models on historical data\n",
    "- **Streaming Use Case**: Detect fraud or anomalies in real time\n",
    "\n",
    "You can stream data continuously, store it, and periodically run batch processes on the stored data.\n",
    "\n",
    "### 📌 Image: Streaming and Batch Components\n",
    "\n",
    "![Streaming and Batch Components](./image/streaming_and_batch_ingestion.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Streaming Ingestion Internals\n",
    "\n",
    "Streaming ingestion uses tools like:\n",
    "- **Apache Kafka**\n",
    "- **Amazon Kinesis**\n",
    "- **Google Pub/Sub**\n",
    "\n",
    "These tools ingest continuous data and forward it to processing layers with minimal delay (seconds or milliseconds).\n",
    "\n",
    "> ⏱ *Example:* Streaming GPS signals from a fleet of delivery trucks to track their location live.\n",
    "\n",
    "### 📌 Image: Streaming Ingestion Architecture\n",
    "\n",
    "![Streaming Ingestion](./image/streaming_ingestion.png)\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Summary\n",
    "\n",
    "- Source systems are where data originates.\n",
    "- Batch is great for periodic, reliable ingestion.\n",
    "- Streaming is useful when near real-time decisions are needed.\n",
    "- Most pipelines use a hybrid of both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79ad8ca",
   "metadata": {},
   "source": [
    "# 📦 Understanding Storage in Data Engineering\n",
    "\n",
    "Data is constantly being created, moved, and stored — whether on your laptop, phone, or in massive cloud systems. As a data engineer, your ability to manage this data depends on how well you understand different **layers of storage**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 1. Raw Ingredients of Storage\n",
    "\n",
    "These are the **fundamental hardware and processes** that make all storage possible.\n",
    "\n",
    "- **Physical components**:\n",
    "  - 💽 Hard Disks (HDD) – cheap and large, but slow.\n",
    "  - ⚡ Solid State Drives (SSD) – faster, more costly.\n",
    "  - 🧠 RAM – very fast but volatile and expensive.\n",
    "\n",
    "- **Software-level processes**:\n",
    "  - Networking\n",
    "  - CPU operations\n",
    "  - Serialization\n",
    "  - Compression\n",
    "  - Caching\n",
    "\n",
    "📸 *Raw ingredients of storage:*\n",
    "\n",
    "![Raw Ingredients](./image/storage.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 🗃️ 2. Storage Systems\n",
    "\n",
    "Built on top of raw ingredients, these systems **organize, store, and manage access** to data.\n",
    "\n",
    "- **Database Management Systems** – For structured data (e.g., PostgreSQL)\n",
    "- **Object Storage** – For blobs/files (e.g., Amazon S3)\n",
    "- **Apache Iceberg/Hudi** – For handling big data tables\n",
    "- **Cache/Memory Systems** – e.g., Redis\n",
    "- **Streaming Storage** – e.g., Kafka for real-time data streams\n",
    "\n",
    "📸 *Common storage systems:*\n",
    "\n",
    "![Storage Systems](./image/storage_systems.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 🧱 3. Storage Abstractions\n",
    "\n",
    "These are **combinations of storage systems** that serve higher-level business needs.\n",
    "\n",
    "- **Data Warehouse** – Optimized for fast queries (e.g., Snowflake, BigQuery)\n",
    "- **Data Lake** – Stores all types of raw data (e.g., AWS S3)\n",
    "- **Data Lakehouse** – Hybrid of the above two (e.g., Databricks Delta Lake)\n",
    "\n",
    "📸 *Types of storage abstractions:*\n",
    "\n",
    "![Storage Abstractions](./image/storage_abstractions.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 🪜 4. Storage Hierarchy Overview\n",
    "\n",
    "Storage can be visualized as a 3-layer hierarchy:\n",
    "\n",
    "1. **Raw Ingredients** – HDDs, SSDs, RAM, Networking\n",
    "2. **Storage Systems** – Databases, object stores, caches\n",
    "3. **Storage Abstractions** – Warehouses, Lakes, Lakehouses\n",
    "\n",
    "As a data engineer, you often work with **abstractions**, but understanding the **lower levels** makes your system faster, cheaper, and more scalable.\n",
    "\n",
    "📸 *Full storage hierarchy:*\n",
    "\n",
    "![Storage Hierarchy](./image/storage_hierarchy.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Summary\n",
    "\n",
    "- You interact with storage systems constantly, even without realizing it.\n",
    "- Storage involves hardware, software, and smart architecture.\n",
    "- **Efficiency and cost** are determined by how well you choose your storage strategy.\n",
    "- Always understand where your data is going and how it's stored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ccc591",
   "metadata": {},
   "source": [
    "# 💾 In-Depth Look: How HDD, SSD, and RAM Actually Work\n",
    "\n",
    "Understanding the **physical mechanisms** behind how data is stored and accessed helps data engineers design systems that are optimized for performance, reliability, and cost.\n",
    "\n",
    "---\n",
    "\n",
    "## 💽 Hard Disk Drives (HDDs)\n",
    "\n",
    "### 🔧 What Happens Inside?\n",
    "\n",
    "An HDD consists of:\n",
    "- **Spinning platters** coated with magnetic material.\n",
    "- A **read/write head** mounted on an actuator arm.\n",
    "- A **motor** that spins the platters at 5400–7200 RPM (or higher).\n",
    "- **Firmware** that controls operations.\n",
    "\n",
    "### 🧲 How Is Data Stored?\n",
    "\n",
    "- Data is stored magnetically in **tiny regions** on the platter called **magnetic domains**.\n",
    "- These regions can be **magnetized in one of two directions**:\n",
    "  - One direction = binary `1`\n",
    "  - Opposite direction = binary `0`\n",
    "- The platter is divided into:\n",
    "  - **Tracks** (concentric circles)\n",
    "  - **Sectors** (segments of tracks)\n",
    "  - **Cylinders** (aligned tracks across platters)\n",
    "\n",
    "### ✍️ Writing Data (Engraving Analogy):\n",
    "\n",
    "- The **write head** generates a magnetic field.\n",
    "- It **flips the magnetic direction** of a region to represent 1s and 0s.\n",
    "- This is similar to an **engraving tool carving marks** on a rotating disc — the tool (head) needs to be **positioned precisely** to write data.\n",
    "\n",
    "### 🔍 Reading Data:\n",
    "\n",
    "- The **read head** senses the magnetic polarity of each domain as the platter spins.\n",
    "- The magnetic change is translated into a stream of binary data.\n",
    "\n",
    "### 🧠 Summary:\n",
    "- ❌ Slower due to mechanical movement.\n",
    "- ✅ Great for large capacity, cheap storage.\n",
    "- ⚠️ Fragile — can be damaged by shocks.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚡ Solid State Drives (SSDs)\n",
    "\n",
    "### 🔧 What Happens Inside?\n",
    "\n",
    "An SSD contains:\n",
    "- **NAND Flash memory chips** (non-volatile)\n",
    "- **Controller** chip to manage read/write operations\n",
    "- No moving parts\n",
    "\n",
    "### 🧠 How Data Is Stored (Electric Charge):\n",
    "\n",
    "- Data is stored in **floating-gate transistors**, which **trap electrons**.\n",
    "- Electrons inside the gate represent binary `1`, and absence of charge is binary `0`.\n",
    "- These transistors are organized into:\n",
    "  - **Cells** (SLC, MLC, TLC depending on how many bits per cell)\n",
    "  - **Pages** (group of cells)\n",
    "  - **Blocks** (group of pages)\n",
    "\n",
    "### ✍️ Writing Data (Charge Manipulation):\n",
    "\n",
    "- To write, a **voltage is applied** to \"trap\" electrons in a floating gate.\n",
    "- To erase, the **voltage releases the trapped electrons**.\n",
    "- This is **slower than reading**, and **blocks must be erased before being rewritten**.\n",
    "\n",
    "### 🔍 Reading Data:\n",
    "\n",
    "- A small voltage is applied.\n",
    "- The presence or absence of current flow tells whether the bit is 0 or 1.\n",
    "\n",
    "### 📦 Summary:\n",
    "- ✅ Fast access, no moving parts.\n",
    "- ⚠️ Limited write cycles — cells wear out over time.\n",
    "- 💸 More expensive than HDDs.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧬 Random Access Memory (RAM)\n",
    "\n",
    "### 🔧 What Happens Inside?\n",
    "\n",
    "RAM consists of:\n",
    "- Millions of **capacitor-transistor pairs**\n",
    "- Each **pair stores one bit** of data\n",
    "- Volatile — **requires constant power** to retain data\n",
    "\n",
    "### ⚡ How Data Is Stored (Capacitor Charging):\n",
    "\n",
    "- A **charged capacitor** = binary `1`\n",
    "- A **discharged capacitor** = binary `0`\n",
    "- Transistors act like gates that allow read/write access to the capacitor\n",
    "\n",
    "### 🔍 Reading Data:\n",
    "\n",
    "- The system checks whether a capacitor holds charge.\n",
    "- This check **discharges the capacitor**, so RAM must **refresh data** constantly (thousands of times per second).\n",
    "\n",
    "### ✍️ Writing Data:\n",
    "\n",
    "- A transistor opens a path to the capacitor.\n",
    "- A voltage is applied to **store charge** (1) or **drain it** (0).\n",
    "\n",
    "### 🧠 Summary:\n",
    "- 🚀 Extremely fast (nanoseconds latency)\n",
    "- ❌ Volatile (data is lost when power goes off)\n",
    "- ✅ Perfect for temporary processing (e.g., active variables in programs)\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Final Comparison (Physically)\n",
    "\n",
    "| Feature          | HDD                            | SSD                                 | RAM                                 |\n",
    "|------------------|---------------------------------|--------------------------------------|--------------------------------------|\n",
    "| Storage Method   | Magnetic domains on platters   | Floating-gate transistors            | Charge in capacitors                 |\n",
    "| Moving Parts     | Yes                             | No                                   | No                                   |\n",
    "| Read/Write Speed | Slow (ms)                       | Fast (μs)                            | Very Fast (ns)                       |\n",
    "| Volatile?        | No                              | No                                   | Yes                                  |\n",
    "| Use Case         | Archive, backups                | OS, active pipelines                 | In-memory compute, temp storage      |\n",
    "| Failure Risk     | Higher (mechanical)             | Lower (but finite write endurance)   | Data lost on power loss              |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Analogy Recap\n",
    "\n",
    "- **HDD** = Like a record player writing grooves on a vinyl disc.\n",
    "- **SSD** = Like a chalkboard where you \"charge\" and \"discharge\" cells.\n",
    "- **RAM** = Like a whiteboard used for calculations — fast, but wiped clean when power is off.\n",
    "\n",
    "---\n",
    "\n",
    "Understanding these differences allows you to pick the right type of storage for your data engineering architecture — whether you're dealing with **hot data**, **cold data**, or **high-speed temporary computation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4bb2a",
   "metadata": {},
   "source": [
    "## 🔄 Data Transformation in the Data Engineering Lifecycle\n",
    "\n",
    "The **transformation stage** is where a data engineer starts to deliver **real business value**. While ingesting and storing raw data is important, it doesn't directly help downstream users like analysts or data scientists.\n",
    "\n",
    "Transformation is the stage where **raw data is turned into something useful**.\n",
    "\n",
    "### 👥 Who Benefits from Transformation?\n",
    "\n",
    "- **Business Analysts**: They might need quick access to clean, structured data like `customer_id`, `product_name`, `quantity`, and `time_of_sale` to generate reports.\n",
    "- **Data Scientists / ML Engineers**: They rely on you to prepare features and cleaned datasets for model training.\n",
    "\n",
    "Transformation includes **3 major components**:\n",
    "- Queries\n",
    "- Modeling\n",
    "- Transformation logic\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Queries\n",
    "\n",
    "A **query** is simply a request to read records from a database or other storage system. SQL is the most commonly used query language.\n",
    "\n",
    "> Poorly written queries can slow down performance, overload databases, or even crash your infrastructure (e.g., row explosion from bad joins).\n",
    "\n",
    "#### 📘 SQL Commands in Transformation\n",
    "\n",
    "- **Data Cleaning**: `DROP`, `TRUNCATE`, `TRIM`, `REPLACE`, `SELECT DISTINCT`\n",
    "- **Data Joining**: `INNER JOIN`, `LEFT JOIN`, `RIGHT JOIN`, `FULL JOIN`, `UNION`\n",
    "- **Data Aggregating**: `SUM`, `AVG`, `COUNT`, `MAX`, `MIN`, `GROUP BY`\n",
    "- **Data Filtering**: `WHERE`, `AND`, `OR`, `IS NULL`, `IS NOT NULL`, `IN`, `LIKE`\n",
    "\n",
    "![Query Commands](./image//sql_commands.png)\n",
    "\n",
    "---\n",
    "\n",
    "### 📐 Data Modeling\n",
    "\n",
    "Data modeling involves choosing the **right structure** to represent data for business needs.\n",
    "\n",
    "- If data comes from **normalized relational databases** (separate tables for orders, products, customers), you may need to **denormalize** it for faster analytics.\n",
    "- Example: A business analyst shouldn't need to join five tables to get product sales data.\n",
    "\n",
    "Good models reflect:\n",
    "- Business logic\n",
    "- Terminology (e.g., how different departments define “customer”)\n",
    "- Reporting or ML requirements\n",
    "\n",
    "You'll learn more about **normalization** and **data modeling** later in the specialization.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔧 Transformation Logic\n",
    "\n",
    "Transformation happens **across multiple stages** of the pipeline:\n",
    "\n",
    "- At the **source system**: timestamps or metadata added\n",
    "- During **ingestion**: data type mapping, standardization\n",
    "- In **streaming pipelines**: records enriched or calculated\n",
    "- Before **machine learning**: features engineered\n",
    "- Before **reporting**: aggregation, schema reshaping\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Examples of Transformation Use Cases\n",
    "\n",
    "#### 🧑‍💻 Business Analyst\n",
    "\n",
    "Goal: Generate daily sales reports\n",
    "\n",
    "![Transformation for Analyst](./image//transformation.png)\n",
    "\n",
    "---\n",
    "\n",
    "#### 👩‍🔬 Data Scientist\n",
    "\n",
    "Goal: Use transformed data for predictive analytics\n",
    "\n",
    "![Transformation for DS](./image/transformation_ds.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eceaf6c",
   "metadata": {},
   "source": [
    "# Serving Data in the Data Engineering Lifecycle\n",
    "\n",
    "Once you've ingested, transformed, and stored your data, you're ready for the final stage of the data engineering lifecycle: **serving**. This is when your work directly creates business value by enabling stakeholders to consume and act on the data.\n",
    "\n",
    "Serving isn't a one-size-fits-all process—it depends on the use case. Let’s break it down.\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Analytics\n",
    "\n",
    "Analytics is about identifying patterns and insights from data. There are 3 main types:\n",
    "\n",
    "### 1. Business Intelligence (BI)\n",
    "\n",
    "- **Example**: The marketing team wants to see **weekly signup trends** from different cities.\n",
    "- **You as a Data Engineer**:\n",
    "  - Ingest user signup logs from the website.\n",
    "  - Transform the data (extract city names, dates, counts).\n",
    "  - Store in a clean reporting table.\n",
    "  - Serve it via a BI dashboard (e.g., Tableau or Looker).\n",
    "\n",
    "### 2. Operational Analytics\n",
    "\n",
    "- **Example**: An e-commerce website wants to **track orders per minute** to detect site crashes or slowdowns.\n",
    "- **You as a Data Engineer**:\n",
    "  - Build a real-time streaming pipeline using tools like Apache Kafka + Spark.\n",
    "  - Transform the incoming order events.\n",
    "  - Push the metrics to a live dashboard.\n",
    "  - Set up alerts for low or zero activity.\n",
    "\n",
    "### 3. Embedded Analytics\n",
    "\n",
    "- **Example**: A food delivery app shows customers their **monthly spend** and **top restaurants**.\n",
    "- **You as a Data Engineer**:\n",
    "  - Join order history, prices, and restaurant data.\n",
    "  - Aggregate spend per month.\n",
    "  - Provide a real-time or scheduled API or dataset to the app team for embedding.\n",
    "\n",
    "![Analytics](./image/analytics.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 🤖 Machine Learning\n",
    "\n",
    "Machine learning requires serving data for model training, inference, and tracking.\n",
    "\n",
    "### Example: Product Recommendation System\n",
    "\n",
    "- **Goal**: Recommend products to users based on their past purchases.\n",
    "- **You as a Data Engineer**:\n",
    "  - Ingest user purchase logs.\n",
    "  - Extract features like categories purchased, price range, time of day.\n",
    "  - Store in a **feature store** (a clean structured table).\n",
    "  - Serve this data for:\n",
    "    - **Training** the ML model.\n",
    "    - **Real-time inference** when a user visits the site.\n",
    "    - Track when the model was trained and with which data (lineage).\n",
    "\n",
    "![Machine Learning](./image/ml.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 Reverse ETL\n",
    "\n",
    "Reverse ETL = Sending cleaned and enhanced data **back to source tools** like CRMs or ad platforms.\n",
    "\n",
    "### Example: Lead Scoring in CRM\n",
    "\n",
    "- **Goal**: Prioritize customers who are most likely to buy.\n",
    "- **You as a Data Engineer**:\n",
    "  - Ingest CRM data (names, interactions).\n",
    "  - Transform into features (e.g., # of visits, email opens).\n",
    "  - Data scientist trains a **lead score model**.\n",
    "  - Serve the lead scores **back into the CRM** so the sales team sees them next to each client’s profile.\n",
    "\n",
    "### Another Simple Example: Email Targeting\n",
    "\n",
    "- Your marketing team wants to send emails only to users **who haven’t logged in for 30 days**.\n",
    "- You write a job that finds those users from your warehouse.\n",
    "- Then push their emails **back to the email platform** (like Mailchimp or HubSpot).\n",
    "\n",
    "![Reverse ETL](./image/reverse_etl.png)\n",
    "\n",
    "---\n",
    "\n",
    "This final stage—**serving**—is where data becomes **useful** and **visible** to the business. Whether it's through dashboards, apps, machine learning models, or external systems, your job is to **deliver clean, usable, timely data** to wherever it's needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c28b76",
   "metadata": {},
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
