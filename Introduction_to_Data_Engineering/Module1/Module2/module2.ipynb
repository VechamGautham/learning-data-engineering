{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bce03ec",
   "metadata": {},
   "source": [
    "# üì¶ Source Systems in Data Engineering\n",
    "\n",
    "In data engineering, the **first step** in the lifecycle is obtaining data from various **source systems**. These are the systems where raw data originates and flows into your pipeline for processing and analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç What Are Source Systems?\n",
    "\n",
    "Source systems are where your data comes from. As a **data engineer**, you don't typically own these systems ‚Äî they are created and maintained by other teams like software developers, third-party vendors, or partner platforms.\n",
    "\n",
    "Your job is to build **pipelines** that consume data from these sources and deliver it to **downstream systems** like dashboards, machine learning models, or data warehouses.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Common Types of Source Systems\n",
    "\n",
    "| Type             | Description                                                                 | Real-World Example                                 |\n",
    "|------------------|-----------------------------------------------------------------------------|----------------------------------------------------|\n",
    "| **Databases**     | Structured data organized into tables or documents                         | Sales transactions from an e-commerce app          |\n",
    "| **Files**         | Unstructured data like CSVs, MP3s, images                                   | Product catalog stored in `products.csv`           |\n",
    "| **APIs**          | On-demand data accessed over the web                                       | Twitter API providing trending hashtags            |\n",
    "| **IoT Devices**   | Real-time data streamed from connected devices                              | GPS trackers on delivery vehicles                  |\n",
    "| **Data Sharing Platforms** | External datasets provided by other organizations                | AWS Data Exchange sharing market research files    |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Why Understanding Source Systems Is Important\n",
    "\n",
    "- Source systems are **not in your control**.\n",
    "- They can **fail**, change format/schema, or update without notice.\n",
    "- If you rely on unstable source systems without planning, your downstream pipelines may **break** silently.\n",
    "\n",
    "> Example: A software team renames or deletes columns in their database without telling you. Your pipeline crashes because it expects columns that no longer exist.\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ù Best Practices\n",
    "\n",
    "- **Collaborate** with the owners of source systems\n",
    "- Understand how the data is **generated and updated**\n",
    "- Know what can **change** ‚Äî and when\n",
    "- Design pipelines to be **resilient** to schema or format changes\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Analogy\n",
    "\n",
    "> Imagine you're a chef (data engineer). Your ingredients (data) come from various suppliers (source systems). One day, a supplier changes packaging or skips delivery without notice ‚Äî your kitchen operations (pipelines) are disrupted unless you're prepared and have good communication.\n",
    "\n",
    "---\n",
    "\n",
    "## üì∑ Diagram: Source Systems ‚Üí Downstream Systems\n",
    "\n",
    "![Source Systems Flow](./image/source_systems.png)\n",
    "\n",
    "In the diagram above:\n",
    "- The left side shows **data sources** like databases, files, APIs, IoT, and data sharing platforms.\n",
    "- These sources **deliver data** through pipelines.\n",
    "- The right side shows **downstream systems** that consume the processed data.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "- **Source systems** are external systems where your pipeline starts.\n",
    "- They include databases, APIs, files, IoT devices, and more.\n",
    "- As a data engineer, your success depends on **understanding, monitoring, and adapting** to these systems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b7de79",
   "metadata": {},
   "source": [
    "# üîÑ Data Ingestion in Data Engineering\n",
    "\n",
    "## 1. Source Systems\n",
    "\n",
    "In the first stage of the data engineering lifecycle, data originates from **source systems**. These are systems that generate or hold the raw data we want to work with.\n",
    "\n",
    "### Common Source Systems:\n",
    "\n",
    "- **Databases** (e.g., sales or customer databases)\n",
    "- **Files** (CSV, JSON, audio, video)\n",
    "- **APIs** (e.g., Twitter API, product data API)\n",
    "- **IoT Devices** (e.g., GPS trackers, sensors)\n",
    "- **Data Sharing Platforms** (e.g., internal dashboards, 3rd-party datasets)\n",
    "\n",
    "These systems may be maintained by:\n",
    "- Other internal teams (e.g., backend engineers)\n",
    "- External vendors\n",
    "- Partner organizations\n",
    "\n",
    "As a data engineer, you don‚Äôt control these systems‚Äîbut your pipelines depend on their structure and consistency.\n",
    "\n",
    "> üîÑ *Analogy:* Think of source systems as different taps (faucets) from which water (data) flows into a treatment plant (your data pipeline). You don‚Äôt control how the taps are built, but you must design your plant to handle the water reliably.\n",
    "\n",
    "### üìå Image: Source Systems Diagram\n",
    "\n",
    "![Source Systems](./images/source_systems.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Frequency of Ingestion\n",
    "\n",
    "Once the data source is identified, you need to decide how **frequently** data should be ingested from it:\n",
    "\n",
    "- **Batch Ingestion**: Collect and move large chunks of data periodically (e.g., every hour/day).\n",
    "- **Streaming Ingestion**: Capture and process events/data in near real-time.\n",
    "\n",
    "> üí° *Example:*  \n",
    "> - Batch: Moving website logs daily into a warehouse for weekly analysis.  \n",
    "> - Stream: Capturing user clicks in real-time to recommend products instantly.\n",
    "\n",
    "> üì¶ *Analogy:*  \n",
    "> - **Batch**: Like collecting mail once a day from a mailbox.  \n",
    "> - **Streaming**: Like receiving WhatsApp messages instantly as they come in.\n",
    "\n",
    "### üìå Image: Frequency of Ingestion\n",
    "\n",
    "![Frequency of Ingestion](./image/ingestion_frequency.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Batch Ingestion\n",
    "\n",
    "**Batch ingestion** means pulling data in chunks at scheduled times or after a set data size.\n",
    "\n",
    "- Often used in analytics and model training\n",
    "- Simple and resource-efficient\n",
    "- Great when real-time updates are not critical\n",
    "\n",
    "> üïí Example: Pulling transaction records from a POS (Point of Sale) system every night at 2 AM for analysis.\n",
    "\n",
    "### üìå Image: Batch Ingestion\n",
    "\n",
    "![Batch Ingestion](./image/batch_ingestion.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Streaming and Batch Together\n",
    "\n",
    "Most real-world systems use a combination of batch and streaming ingestion.\n",
    "\n",
    "- **Batch Use Case**: Train ML models on historical data\n",
    "- **Streaming Use Case**: Detect fraud or anomalies in real time\n",
    "\n",
    "You can stream data continuously, store it, and periodically run batch processes on the stored data.\n",
    "\n",
    "### üìå Image: Streaming and Batch Components\n",
    "\n",
    "![Streaming and Batch Components](./image/streaming_and_batch_ingestion.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Streaming Ingestion Internals\n",
    "\n",
    "Streaming ingestion uses tools like:\n",
    "- **Apache Kafka**\n",
    "- **Amazon Kinesis**\n",
    "- **Google Pub/Sub**\n",
    "\n",
    "These tools ingest continuous data and forward it to processing layers with minimal delay (seconds or milliseconds).\n",
    "\n",
    "> ‚è± *Example:* Streaming GPS signals from a fleet of delivery trucks to track their location live.\n",
    "\n",
    "### üìå Image: Streaming Ingestion Architecture\n",
    "\n",
    "![Streaming Ingestion](./image/streaming_ingestion.png)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "- Source systems are where data originates.\n",
    "- Batch is great for periodic, reliable ingestion.\n",
    "- Streaming is useful when near real-time decisions are needed.\n",
    "- Most pipelines use a hybrid of both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79ad8ca",
   "metadata": {},
   "source": [
    "# üì¶ Understanding Storage in Data Engineering\n",
    "\n",
    "Data is constantly being created, moved, and stored ‚Äî whether on your laptop, phone, or in massive cloud systems. As a data engineer, your ability to manage this data depends on how well you understand different **layers of storage**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß 1. Raw Ingredients of Storage\n",
    "\n",
    "These are the **fundamental hardware and processes** that make all storage possible.\n",
    "\n",
    "- **Physical components**:\n",
    "  - üíΩ Hard Disks (HDD) ‚Äì cheap and large, but slow.\n",
    "  - ‚ö° Solid State Drives (SSD) ‚Äì faster, more costly.\n",
    "  - üß† RAM ‚Äì very fast but volatile and expensive.\n",
    "\n",
    "- **Software-level processes**:\n",
    "  - Networking\n",
    "  - CPU operations\n",
    "  - Serialization\n",
    "  - Compression\n",
    "  - Caching\n",
    "\n",
    "üì∏ *Raw ingredients of storage:*\n",
    "\n",
    "![Raw Ingredients](./image/storage.png)\n",
    "\n",
    "---\n",
    "\n",
    "## üóÉÔ∏è 2. Storage Systems\n",
    "\n",
    "Built on top of raw ingredients, these systems **organize, store, and manage access** to data.\n",
    "\n",
    "- **Database Management Systems** ‚Äì For structured data (e.g., PostgreSQL)\n",
    "- **Object Storage** ‚Äì For blobs/files (e.g., Amazon S3)\n",
    "- **Apache Iceberg/Hudi** ‚Äì For handling big data tables\n",
    "- **Cache/Memory Systems** ‚Äì e.g., Redis\n",
    "- **Streaming Storage** ‚Äì e.g., Kafka for real-time data streams\n",
    "\n",
    "üì∏ *Common storage systems:*\n",
    "\n",
    "![Storage Systems](./image/storage_systems.png)\n",
    "\n",
    "---\n",
    "\n",
    "## üß± 3. Storage Abstractions\n",
    "\n",
    "These are **combinations of storage systems** that serve higher-level business needs.\n",
    "\n",
    "- **Data Warehouse** ‚Äì Optimized for fast queries (e.g., Snowflake, BigQuery)\n",
    "- **Data Lake** ‚Äì Stores all types of raw data (e.g., AWS S3)\n",
    "- **Data Lakehouse** ‚Äì Hybrid of the above two (e.g., Databricks Delta Lake)\n",
    "\n",
    "üì∏ *Types of storage abstractions:*\n",
    "\n",
    "![Storage Abstractions](./image/storage_abstractions.png)\n",
    "\n",
    "---\n",
    "\n",
    "## ü™ú 4. Storage Hierarchy Overview\n",
    "\n",
    "Storage can be visualized as a 3-layer hierarchy:\n",
    "\n",
    "1. **Raw Ingredients** ‚Äì HDDs, SSDs, RAM, Networking\n",
    "2. **Storage Systems** ‚Äì Databases, object stores, caches\n",
    "3. **Storage Abstractions** ‚Äì Warehouses, Lakes, Lakehouses\n",
    "\n",
    "As a data engineer, you often work with **abstractions**, but understanding the **lower levels** makes your system faster, cheaper, and more scalable.\n",
    "\n",
    "üì∏ *Full storage hierarchy:*\n",
    "\n",
    "![Storage Hierarchy](./image/storage_hierarchy.png)\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Summary\n",
    "\n",
    "- You interact with storage systems constantly, even without realizing it.\n",
    "- Storage involves hardware, software, and smart architecture.\n",
    "- **Efficiency and cost** are determined by how well you choose your storage strategy.\n",
    "- Always understand where your data is going and how it's stored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ccc591",
   "metadata": {},
   "source": [
    "# üíæ In-Depth Look: How HDD, SSD, and RAM Actually Work\n",
    "\n",
    "Understanding the **physical mechanisms** behind how data is stored and accessed helps data engineers design systems that are optimized for performance, reliability, and cost.\n",
    "\n",
    "---\n",
    "\n",
    "## üíΩ Hard Disk Drives (HDDs)\n",
    "\n",
    "### üîß What Happens Inside?\n",
    "\n",
    "An HDD consists of:\n",
    "- **Spinning platters** coated with magnetic material.\n",
    "- A **read/write head** mounted on an actuator arm.\n",
    "- A **motor** that spins the platters at 5400‚Äì7200 RPM (or higher).\n",
    "- **Firmware** that controls operations.\n",
    "\n",
    "### üß≤ How Is Data Stored?\n",
    "\n",
    "- Data is stored magnetically in **tiny regions** on the platter called **magnetic domains**.\n",
    "- These regions can be **magnetized in one of two directions**:\n",
    "  - One direction = binary `1`\n",
    "  - Opposite direction = binary `0`\n",
    "- The platter is divided into:\n",
    "  - **Tracks** (concentric circles)\n",
    "  - **Sectors** (segments of tracks)\n",
    "  - **Cylinders** (aligned tracks across platters)\n",
    "\n",
    "### ‚úçÔ∏è Writing Data (Engraving Analogy):\n",
    "\n",
    "- The **write head** generates a magnetic field.\n",
    "- It **flips the magnetic direction** of a region to represent 1s and 0s.\n",
    "- This is similar to an **engraving tool carving marks** on a rotating disc ‚Äî the tool (head) needs to be **positioned precisely** to write data.\n",
    "\n",
    "### üîç Reading Data:\n",
    "\n",
    "- The **read head** senses the magnetic polarity of each domain as the platter spins.\n",
    "- The magnetic change is translated into a stream of binary data.\n",
    "\n",
    "### üß† Summary:\n",
    "- ‚ùå Slower due to mechanical movement.\n",
    "- ‚úÖ Great for large capacity, cheap storage.\n",
    "- ‚ö†Ô∏è Fragile ‚Äî can be damaged by shocks.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Solid State Drives (SSDs)\n",
    "\n",
    "### üîß What Happens Inside?\n",
    "\n",
    "An SSD contains:\n",
    "- **NAND Flash memory chips** (non-volatile)\n",
    "- **Controller** chip to manage read/write operations\n",
    "- No moving parts\n",
    "\n",
    "### üß† How Data Is Stored (Electric Charge):\n",
    "\n",
    "- Data is stored in **floating-gate transistors**, which **trap electrons**.\n",
    "- Electrons inside the gate represent binary `1`, and absence of charge is binary `0`.\n",
    "- These transistors are organized into:\n",
    "  - **Cells** (SLC, MLC, TLC depending on how many bits per cell)\n",
    "  - **Pages** (group of cells)\n",
    "  - **Blocks** (group of pages)\n",
    "\n",
    "### ‚úçÔ∏è Writing Data (Charge Manipulation):\n",
    "\n",
    "- To write, a **voltage is applied** to \"trap\" electrons in a floating gate.\n",
    "- To erase, the **voltage releases the trapped electrons**.\n",
    "- This is **slower than reading**, and **blocks must be erased before being rewritten**.\n",
    "\n",
    "### üîç Reading Data:\n",
    "\n",
    "- A small voltage is applied.\n",
    "- The presence or absence of current flow tells whether the bit is 0 or 1.\n",
    "\n",
    "### üì¶ Summary:\n",
    "- ‚úÖ Fast access, no moving parts.\n",
    "- ‚ö†Ô∏è Limited write cycles ‚Äî cells wear out over time.\n",
    "- üí∏ More expensive than HDDs.\n",
    "\n",
    "---\n",
    "\n",
    "## üß¨ Random Access Memory (RAM)\n",
    "\n",
    "### üîß What Happens Inside?\n",
    "\n",
    "RAM consists of:\n",
    "- Millions of **capacitor-transistor pairs**\n",
    "- Each **pair stores one bit** of data\n",
    "- Volatile ‚Äî **requires constant power** to retain data\n",
    "\n",
    "### ‚ö° How Data Is Stored (Capacitor Charging):\n",
    "\n",
    "- A **charged capacitor** = binary `1`\n",
    "- A **discharged capacitor** = binary `0`\n",
    "- Transistors act like gates that allow read/write access to the capacitor\n",
    "\n",
    "### üîç Reading Data:\n",
    "\n",
    "- The system checks whether a capacitor holds charge.\n",
    "- This check **discharges the capacitor**, so RAM must **refresh data** constantly (thousands of times per second).\n",
    "\n",
    "### ‚úçÔ∏è Writing Data:\n",
    "\n",
    "- A transistor opens a path to the capacitor.\n",
    "- A voltage is applied to **store charge** (1) or **drain it** (0).\n",
    "\n",
    "### üß† Summary:\n",
    "- üöÄ Extremely fast (nanoseconds latency)\n",
    "- ‚ùå Volatile (data is lost when power goes off)\n",
    "- ‚úÖ Perfect for temporary processing (e.g., active variables in programs)\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Final Comparison (Physically)\n",
    "\n",
    "| Feature          | HDD                            | SSD                                 | RAM                                 |\n",
    "|------------------|---------------------------------|--------------------------------------|--------------------------------------|\n",
    "| Storage Method   | Magnetic domains on platters   | Floating-gate transistors            | Charge in capacitors                 |\n",
    "| Moving Parts     | Yes                             | No                                   | No                                   |\n",
    "| Read/Write Speed | Slow (ms)                       | Fast (Œºs)                            | Very Fast (ns)                       |\n",
    "| Volatile?        | No                              | No                                   | Yes                                  |\n",
    "| Use Case         | Archive, backups                | OS, active pipelines                 | In-memory compute, temp storage      |\n",
    "| Failure Risk     | Higher (mechanical)             | Lower (but finite write endurance)   | Data lost on power loss              |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Analogy Recap\n",
    "\n",
    "- **HDD** = Like a record player writing grooves on a vinyl disc.\n",
    "- **SSD** = Like a chalkboard where you \"charge\" and \"discharge\" cells.\n",
    "- **RAM** = Like a whiteboard used for calculations ‚Äî fast, but wiped clean when power is off.\n",
    "\n",
    "---\n",
    "\n",
    "Understanding these differences allows you to pick the right type of storage for your data engineering architecture ‚Äî whether you're dealing with **hot data**, **cold data**, or **high-speed temporary computation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4bb2a",
   "metadata": {},
   "source": [
    "## üîÑ Data Transformation in the Data Engineering Lifecycle\n",
    "\n",
    "The **transformation stage** is where a data engineer starts to deliver **real business value**. While ingesting and storing raw data is important, it doesn't directly help downstream users like analysts or data scientists.\n",
    "\n",
    "Transformation is the stage where **raw data is turned into something useful**.\n",
    "\n",
    "### üë• Who Benefits from Transformation?\n",
    "\n",
    "- **Business Analysts**: They might need quick access to clean, structured data like `customer_id`, `product_name`, `quantity`, and `time_of_sale` to generate reports.\n",
    "- **Data Scientists / ML Engineers**: They rely on you to prepare features and cleaned datasets for model training.\n",
    "\n",
    "Transformation includes **3 major components**:\n",
    "- Queries\n",
    "- Modeling\n",
    "- Transformation logic\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Queries\n",
    "\n",
    "A **query** is simply a request to read records from a database or other storage system. SQL is the most commonly used query language.\n",
    "\n",
    "> Poorly written queries can slow down performance, overload databases, or even crash your infrastructure (e.g., row explosion from bad joins).\n",
    "\n",
    "#### üìò SQL Commands in Transformation\n",
    "\n",
    "- **Data Cleaning**: `DROP`, `TRUNCATE`, `TRIM`, `REPLACE`, `SELECT DISTINCT`\n",
    "- **Data Joining**: `INNER JOIN`, `LEFT JOIN`, `RIGHT JOIN`, `FULL JOIN`, `UNION`\n",
    "- **Data Aggregating**: `SUM`, `AVG`, `COUNT`, `MAX`, `MIN`, `GROUP BY`\n",
    "- **Data Filtering**: `WHERE`, `AND`, `OR`, `IS NULL`, `IS NOT NULL`, `IN`, `LIKE`\n",
    "\n",
    "![Query Commands](./image//sql_commands.png)\n",
    "\n",
    "---\n",
    "\n",
    "### üìê Data Modeling\n",
    "\n",
    "Data modeling involves choosing the **right structure** to represent data for business needs.\n",
    "\n",
    "- If data comes from **normalized relational databases** (separate tables for orders, products, customers), you may need to **denormalize** it for faster analytics.\n",
    "- Example: A business analyst shouldn't need to join five tables to get product sales data.\n",
    "\n",
    "Good models reflect:\n",
    "- Business logic\n",
    "- Terminology (e.g., how different departments define ‚Äúcustomer‚Äù)\n",
    "- Reporting or ML requirements\n",
    "\n",
    "You'll learn more about **normalization** and **data modeling** later in the specialization.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Transformation Logic\n",
    "\n",
    "Transformation happens **across multiple stages** of the pipeline:\n",
    "\n",
    "- At the **source system**: timestamps or metadata added\n",
    "- During **ingestion**: data type mapping, standardization\n",
    "- In **streaming pipelines**: records enriched or calculated\n",
    "- Before **machine learning**: features engineered\n",
    "- Before **reporting**: aggregation, schema reshaping\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Examples of Transformation Use Cases\n",
    "\n",
    "#### üßë‚Äçüíª Business Analyst\n",
    "\n",
    "Goal: Generate daily sales reports\n",
    "\n",
    "![Transformation for Analyst](./image//transformation.png)\n",
    "\n",
    "---\n",
    "\n",
    "#### üë©‚Äçüî¨ Data Scientist\n",
    "\n",
    "Goal: Use transformed data for predictive analytics\n",
    "\n",
    "![Transformation for DS](./image/transformation_ds.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eceaf6c",
   "metadata": {},
   "source": [
    "# Serving Data in the Data Engineering Lifecycle\n",
    "\n",
    "Once you've ingested, transformed, and stored your data, you're ready for the final stage of the data engineering lifecycle: **serving**. This is when your work directly creates business value by enabling stakeholders to consume and act on the data.\n",
    "\n",
    "Serving isn't a one-size-fits-all process‚Äîit depends on the use case. Let‚Äôs break it down.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Analytics\n",
    "\n",
    "Analytics is about identifying patterns and insights from data. There are 3 main types:\n",
    "\n",
    "### 1. Business Intelligence (BI)\n",
    "\n",
    "- **Example**: The marketing team wants to see **weekly signup trends** from different cities.\n",
    "- **You as a Data Engineer**:\n",
    "  - Ingest user signup logs from the website.\n",
    "  - Transform the data (extract city names, dates, counts).\n",
    "  - Store in a clean reporting table.\n",
    "  - Serve it via a BI dashboard (e.g., Tableau or Looker).\n",
    "\n",
    "### 2. Operational Analytics\n",
    "\n",
    "- **Example**: An e-commerce website wants to **track orders per minute** to detect site crashes or slowdowns.\n",
    "- **You as a Data Engineer**:\n",
    "  - Build a real-time streaming pipeline using tools like Apache Kafka + Spark.\n",
    "  - Transform the incoming order events.\n",
    "  - Push the metrics to a live dashboard.\n",
    "  - Set up alerts for low or zero activity.\n",
    "\n",
    "### 3. Embedded Analytics\n",
    "\n",
    "- **Example**: A food delivery app shows customers their **monthly spend** and **top restaurants**.\n",
    "- **You as a Data Engineer**:\n",
    "  - Join order history, prices, and restaurant data.\n",
    "  - Aggregate spend per month.\n",
    "  - Provide a real-time or scheduled API or dataset to the app team for embedding.\n",
    "\n",
    "![Analytics](./image/analytics.png)\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ñ Machine Learning\n",
    "\n",
    "Machine learning requires serving data for model training, inference, and tracking.\n",
    "\n",
    "### Example: Product Recommendation System\n",
    "\n",
    "- **Goal**: Recommend products to users based on their past purchases.\n",
    "- **You as a Data Engineer**:\n",
    "  - Ingest user purchase logs.\n",
    "  - Extract features like categories purchased, price range, time of day.\n",
    "  - Store in a **feature store** (a clean structured table).\n",
    "  - Serve this data for:\n",
    "    - **Training** the ML model.\n",
    "    - **Real-time inference** when a user visits the site.\n",
    "    - Track when the model was trained and with which data (lineage).\n",
    "\n",
    "![Machine Learning](./image/ml.png)\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Reverse ETL\n",
    "\n",
    "Reverse ETL = Sending cleaned and enhanced data **back to source tools** like CRMs or ad platforms.\n",
    "\n",
    "### Example: Lead Scoring in CRM\n",
    "\n",
    "- **Goal**: Prioritize customers who are most likely to buy.\n",
    "- **You as a Data Engineer**:\n",
    "  - Ingest CRM data (names, interactions).\n",
    "  - Transform into features (e.g., # of visits, email opens).\n",
    "  - Data scientist trains a **lead score model**.\n",
    "  - Serve the lead scores **back into the CRM** so the sales team sees them next to each client‚Äôs profile.\n",
    "\n",
    "### Another Simple Example: Email Targeting\n",
    "\n",
    "- Your marketing team wants to send emails only to users **who haven‚Äôt logged in for 30 days**.\n",
    "- You write a job that finds those users from your warehouse.\n",
    "- Then push their emails **back to the email platform** (like Mailchimp or HubSpot).\n",
    "\n",
    "![Reverse ETL](./image/reverse_etl.png)\n",
    "\n",
    "---\n",
    "\n",
    "This final stage‚Äî**serving**‚Äîis where data becomes **useful** and **visible** to the business. Whether it's through dashboards, apps, machine learning models, or external systems, your job is to **deliver clean, usable, timely data** to wherever it's needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e9d629",
   "metadata": {},
   "source": [
    "## üåä Undercurrents of the Data Engineering Lifecycle\n",
    "\n",
    "In data engineering, **undercurrents** are foundational themes that apply across all stages of the lifecycle ‚Äî from ingestion and transformation to storage and serving.\n",
    "\n",
    "They‚Äôre not specific steps but **core disciplines** that support and strengthen your entire data system.\n",
    "\n",
    "---\n",
    "\n",
    "### üîê 1. Security\n",
    "\n",
    "Security ensures data is protected from unauthorized access, leaks, and misuse.\n",
    "\n",
    "- Apply **least privilege access**\n",
    "- Use **IAM**, encryption, and secure network protocols\n",
    "- Prevent security breaches due to human error or misconfigurations\n",
    "- Build a **culture of security**, not just compliance\n",
    "\n",
    "---\n",
    "\n",
    "### üóÇÔ∏è 2. Data Management\n",
    "\n",
    "Effective data management ensures your data is organized, traceable, and high quality.\n",
    "\n",
    "- Maintain **metadata catalogs**\n",
    "- Enable **data lineage** tracking (where the data came from and how it changed)\n",
    "- Handle **schema evolution** as data changes over time\n",
    "- Keep audit logs for compliance and monitoring\n",
    "\n",
    "---\n",
    "\n",
    "### üèóÔ∏è 3. Data Architecture\n",
    "\n",
    "Data architecture is the blueprint of how your data flows and is structured.\n",
    "\n",
    "- Choose between **batch** or **streaming**\n",
    "- Design **data lakes**, **data warehouses**, or **lakehouses**\n",
    "- Select the right **storage formats** (e.g., Parquet, Avro, Delta)\n",
    "- Structure data for performance, cost, and scalability\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ 4. DataOps & Orchestration\n",
    "\n",
    "This undercurrent focuses on operationalizing and automating data workflows.\n",
    "\n",
    "- Use tools like **Apache Airflow**, **Dagster**, or **Prefect**\n",
    "- Define **data pipelines** as code\n",
    "- Monitor pipelines and handle failures gracefully\n",
    "- Enable **continuous integration/deployment** for data workflows\n",
    "\n",
    "---\n",
    "\n",
    "### üßë‚Äçüíª 5. Software Engineering Practices\n",
    "\n",
    "Data engineers are also software engineers.\n",
    "\n",
    "- Write **modular, testable, reusable** code\n",
    "- Use **version control** (Git), code reviews, and CI/CD pipelines\n",
    "- Document data systems and code\n",
    "- Follow testing best practices (unit tests, integration tests)\n",
    "\n",
    "---\n",
    "\n",
    "These undercurrents are not isolated ‚Äî they all work together to build resilient, secure, scalable, and efficient data platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b5fbe7",
   "metadata": {},
   "source": [
    "## üîê Security in Data Engineering\n",
    "\n",
    "As a data engineer, you work with sensitive and valuable data. You're responsible for making sure this data is safe ‚Äî from both external attackers and internal misuse.\n",
    "\n",
    "### üß† Defensive Mindset\n",
    "\n",
    "Security starts with your behavior:\n",
    "\n",
    "- **Be cautious with sensitive data** ‚Äî never share passwords or credentials casually.\n",
    "- **Design for potential attacks** ‚Äî expect phishing, impersonation, and social engineering attempts.\n",
    "\n",
    "![Defensive Mindset](./image/defensive_mindset.png)\n",
    "\n",
    "---\n",
    "\n",
    "### ‚òÅÔ∏è Security in the Cloud\n",
    "\n",
    "Most modern pipelines are cloud-native. That means understanding cloud security is essential.\n",
    "\n",
    "#### Key Concepts:\n",
    "\n",
    "- **IAM (Identity and Access Management):**  \n",
    "  Control who can access what, and under what conditions.\n",
    "\n",
    "- **Encryption Methods:**  \n",
    "  Encrypt data at rest and in transit.\n",
    "\n",
    "- **Networking Protocols:**  \n",
    "  Use secure networks, VPNs, and firewalls.\n",
    "\n",
    "üìå Example:  \n",
    "Only let specific users run queries on sensitive tables using IAM roles. Encrypt backups using KMS.\n",
    "\n",
    "![Security in the Cloud](./image/security_in_cloud.png)\n",
    "\n",
    "---\n",
    "\n",
    "### üõë Principle of Least Privilege\n",
    "\n",
    "Only give users the minimum access they need ‚Äî and only for as long as they need it.\n",
    "\n",
    "üìå Example:  \n",
    "A dashboard user shouldn‚Äôt have write access to raw production data.\n",
    "\n",
    "---\n",
    "\n",
    "### üßØ Avoid Unnecessary Sensitive Data\n",
    "\n",
    "If there‚Äôs no good reason to store data like passwords, SSNs, or credit cards ‚Äî don‚Äôt store it at all.\n",
    "\n",
    "---\n",
    "\n",
    "### üö´ Human Mistakes = Real Risk\n",
    "\n",
    "Most leaks happen because someone:\n",
    "\n",
    "- Made a bucket public by accident\n",
    "- Reused a weak password\n",
    "- Clicked on a phishing link\n",
    "- Pasted credentials into public GitHub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d90618",
   "metadata": {},
   "source": [
    "## üìö Data Management for Data Engineers\n",
    "\n",
    "Data management is the practice of treating data as a valuable asset ‚Äî just like money or property. It involves organizing, protecting, and making data useful across its lifecycle. Without good data management, even the best infrastructure is useless.\n",
    "\n",
    "One of the most respected sources on this topic is **DAMA International**, which created the **DMBOK** (Data Management Book of Knowledge). It outlines **11 key data knowledge areas**, all centered around **Data Governance**.\n",
    "\n",
    "### üåÄ 11 Data Knowledge Areas\n",
    "\n",
    "![Data Management Wheel](./image/11_data_knowledge_areas.png)\n",
    "\n",
    "Each slice of the wheel represents an essential discipline:\n",
    "\n",
    "- **Data Governance**: Sets policies, roles, and responsibilities for data.\n",
    "- **Data Architecture**: How data is structured across systems.\n",
    "- **Data Modeling & Design**: Defining how data is stored (tables, schema).\n",
    "- **Data Storage & Operations**: Managing how and where data is stored.\n",
    "- **Data Integration & Interoperability**: Combining data from multiple systems.\n",
    "- **Data Security**: Protecting sensitive information.\n",
    "- **Reference & Master Data**: Maintaining core business data (e.g., product codes).\n",
    "- **Metadata**: Data that describes other data (e.g., table descriptions).\n",
    "- **Data Warehousing & BI**: Centralizing data for analysis and reporting.\n",
    "- **Document & Content Management**: Organizing unstructured documents.\n",
    "- **Data Quality**: Ensuring accuracy, completeness, and reliability.\n",
    "\n",
    "### üèóÔ∏è What‚Äôs Your Role as a Data Engineer?\n",
    "\n",
    "As a data engineer, you don‚Äôt have to master all 11 areas ‚Äî but you‚Äôll directly work on:\n",
    "\n",
    "- **Data Integration**: Connecting APIs and systems.\n",
    "- **Data Storage**: Setting up data lakes, warehouses.\n",
    "- **Data Quality**: Validating data through rules and checks.\n",
    "- **Metadata**: Tagging datasets so others understand them.\n",
    "- **Data Governance**: Applying access control and logging usage.\n",
    "\n",
    "### üß† Real-World Analogy: A Warehouse\n",
    "\n",
    "Imagine you're running a warehouse:\n",
    "- Only trusted people can enter üîê (Security)\n",
    "- Every item is labeled clearly üè∑Ô∏è (Metadata)\n",
    "- Nothing is expired or broken ‚úÖ (Data Quality)\n",
    "- You can combine items from different suppliers üîÑ (Integration)\n",
    "\n",
    "A good data management system works just like that ‚Äî but for digital data.\n",
    "\n",
    "### üíº Real Example: Zomato\n",
    "\n",
    "At Zomato:\n",
    "- **Governance** defines what ‚Äúactive user‚Äù means.\n",
    "- **Quality checks** ensure delivery data is accurate.\n",
    "- **Metadata** helps teams understand the schema.\n",
    "- **Integration** merges app + restaurant data into one view.\n",
    "\n",
    "---\n",
    "\n",
    "With strong data management, organizations can build trust, drive insights, and avoid costly mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f6f586",
   "metadata": {},
   "source": [
    "# üèõÔ∏è Data Architecture\n",
    "\n",
    "Data Architecture is like a **blueprint or roadmap** for how data systems are designed to meet current and future organizational needs. It‚Äôs not a one-time task ‚Äî it‚Äôs an **ongoing process** that adapts as business goals, technology, and data evolve.\n",
    "\n",
    "> ‚ÄúData architecture is the design of systems to support the evolving data needs of an enterprise, achieved by flexible and reversible decisions reached through a careful evaluation of trade-offs.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Why It Matters (for Data Engineers)\n",
    "\n",
    "- In large companies: Architects design ‚Üí Engineers implement\n",
    "- In startups: You may be both architect and engineer\n",
    "- **Thinking like an architect** helps you:\n",
    "  - Choose better tools\n",
    "  - Solve scalability issues\n",
    "  - Avoid costly mistakes\n",
    "  - Lead teams as you grow\n",
    "\n",
    "---\n",
    "\n",
    "## üß± Real-Life Analogy\n",
    "\n",
    "Imagine designing a **modular kitchen**:\n",
    "\n",
    "- If you design with **flexibility**, you can upgrade appliances easily.\n",
    "- If not, changing even one part requires **tearing the whole kitchen down**.\n",
    "\n",
    "Good data architecture works the same way ‚Äî **flexibility and reversibility** are key.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 9 Principles of Good Data Architecture\n",
    "\n",
    "| # | Principle | Description |\n",
    "|---|-----------|-------------|\n",
    "| 1Ô∏è‚É£ | **Choose common components wisely** | Pick tools that multiple teams can use efficiently |\n",
    "| 2Ô∏è‚É£ | **Plan for failure** | Expect and design for things to break |\n",
    "| 3Ô∏è‚É£ | **Architect for scalability** | Make it easy to scale up and down with demand |\n",
    "| 4Ô∏è‚É£ | **Architecture is leadership** | Good architecture sets a strong direction for teams |\n",
    "| 5Ô∏è‚É£ | **Always be architecting** | Revisit your architecture regularly as needs evolve |\n",
    "| 6Ô∏è‚É£ | **Build loosely coupled systems** | Design components to operate independently |\n",
    "| 7Ô∏è‚É£ | **Make reversible decisions** | Use plug-and-play components that can be changed later |\n",
    "| 8Ô∏è‚É£ | **Prioritize security** | Use principles like least privilege and zero trust |\n",
    "| 9Ô∏è‚É£ | **Embrace FinOps** | Design for both cost-efficiency and performance |\n",
    "\n",
    "---\n",
    "\n",
    "## üßë‚Äçüíª Real-World Example\n",
    "\n",
    "### üü¢ Music Streaming Service Data Platform\n",
    "\n",
    "- Use **Kafka** to stream live listening events (loosely coupled)\n",
    "- Store results in **Snowflake** (can reverse to BigQuery)\n",
    "- Apply **IAM roles and encryption** (security)\n",
    "- Scale systems up at peak hours, down during low traffic (scalable + FinOps)\n",
    "\n",
    "---\n",
    "\n",
    "üß† **Takeaway:** Whether you are an engineer or architect, always think of **designing systems that adapt, scale, and evolve** ‚Äî and never forget to bake in security and cost-awareness from day one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
