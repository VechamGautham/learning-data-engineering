{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e7dfbb",
   "metadata": {},
   "source": [
    "# What is Data Engineering?\n",
    "\n",
    "**Data Engineering** is the practice of designing, building, and maintaining systems that enable the collection, storage, processing, and analysis of data at scale.\n",
    "\n",
    "It provides the foundation that allows data scientists, analysts, and business teams to work with clean, reliable, and accessible data.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Responsibilities of a Data Engineer:\n",
    "\n",
    "- **Build data pipelines** to move data from source systems to data warehouses or data lakes.\n",
    "- **Clean and transform raw data** so it's usable for analytics and machine learning.\n",
    "- **Design scalable architectures** for storing and querying large volumes of data.\n",
    "- **Ensure data quality, security, and governance.**\n",
    "- **Collaborate with stakeholders** to understand data needs and translate them into technical systems.\n",
    "\n",
    "---\n",
    "\n",
    "## Why It Matters\n",
    "\n",
    "Without data engineering:\n",
    "- Data scientists and analysts waste time trying to access or clean data.\n",
    "- Business decisions may be based on incomplete or incorrect data.\n",
    "- Machine learning models cannot be trained or deployed effectively.\n",
    "\n",
    "In short, **Data Engineering powers the entire data ecosystem** in a company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6c7907",
   "metadata": {},
   "source": [
    "# The Evolution of Data Engineering\n",
    "\n",
    "In the early days, **data engineering** didn't exist as a dedicated role. The original data engineers were simply **software engineers**, focused on building applications. The **data** generated by these applications was treated as a byproduct ‚Äî useful mainly for **debugging** or **monitoring**, but not much else.\n",
    "\n",
    "This data was like **\"exhaust\" from a car** ‚Äî a natural outcome, but not something with standalone value.\n",
    "\n",
    "---\n",
    "\n",
    "Over time, as companies recognized the **intrinsic value of data**, especially with the rise in **volume and variety**, the role of engineers shifted. Engineers started building systems *specifically* for data ingestion, transformation, and delivery. This led to the formalization of the **Data Engineer** role.\n",
    "\n",
    "---\n",
    "\n",
    "## What Is Data Engineering?\n",
    "\n",
    "In the book *Fundamentals of Data Engineering*, the authors Joe Reis and Matt Housley define data engineering as:\n",
    "\n",
    "> **\"The development, implementation, and maintenance of systems and processes that take in raw data and produce high-quality, consistent information that supports downstream use cases, such as analysis and machine learning.\"**\n",
    "\n",
    "---\n",
    "\n",
    "### Data Engineering Sits at the Intersection of:\n",
    "\n",
    "- **Security**\n",
    "- **Data Management**\n",
    "- **DataOps**\n",
    "- **Data Architecture**\n",
    "- **Orchestration**\n",
    "- **Software Engineering**\n",
    "\n",
    "These are referred to as the **undercurrents** of data engineering ‚Äî they apply across every stage of the data life cycle.\n",
    "\n",
    "---\n",
    "\n",
    "## The Data Engineering Life Cycle\n",
    "\n",
    "The lifecycle can be visualized as a flow from data generation to end use cases:\n",
    "\n",
    "1. **Data Generation & Source Systems**  \n",
    "   (e.g. app logs, sensor data, uploaded files)\n",
    "\n",
    "2. **Ingestion**  \n",
    "   (bringing raw data into your systems)\n",
    "\n",
    "3. **Storage**  \n",
    "   (saving raw or processed data efficiently)\n",
    "\n",
    "4. **Transformation**  \n",
    "   (cleaning, filtering, enriching, and shaping the data)\n",
    "\n",
    "5. **Serving**  \n",
    "   (making processed data available for use)\n",
    "\n",
    "6. **End Use Cases**  \n",
    "   (analytics, machine learning, reverse ETL)\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Data Engineering Lifecycle Diagram\n",
    "![data engineering life cycle](image/data_engineering_lifecycle.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Final Thought\n",
    "\n",
    "As a Data Engineer, your goal is to **transform raw data into useful, reliable, and accessible information** ‚Äî supporting analytics, machine learning, and other business needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948b3cee",
   "metadata": {},
   "source": [
    "# History of Data Engineering ‚Äì What I Understood\n",
    "\n",
    "From the video, I understood that data has always existed ‚Äî not just in the form of numbers or words, but also as natural signals like wind, sound, or light. But the kind of data we focus on in data engineering is **digitally recorded data**, the type that can be stored on a computer and used for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## The Early Days (1960s‚Äì1980s)\n",
    "\n",
    "Data engineering didn‚Äôt start as a formal role. In the 1960s, computers introduced the first **digital databases**. In the 1970s, IBM engineers created **relational databases** and **SQL** (Structured Query Language), which is still widely used today.\n",
    "\n",
    "In the 1980s, **Bill Inmon** came up with the idea of the **data warehouse**, which helped businesses transform and organize data for better decision-making. These early efforts laid the foundation for what would eventually become the field of data engineering.\n",
    "\n",
    "---\n",
    "\n",
    "## The 1990s: Growth of BI and the Internet\n",
    "\n",
    "In the 1990s, companies began building **data pipelines** to support **Business Intelligence (BI)** and reporting. Two important names during this time were **Bill Inmon** and **Ralph Kimball**, who proposed different approaches to data modeling for analytics.\n",
    "\n",
    "Also, the rise of the **Internet** (and companies like Amazon) created massive growth in data. This made data pipelines and infrastructure even more important.\n",
    "\n",
    "---\n",
    "\n",
    "## The 2000s: Big Data Era Begins\n",
    "\n",
    "In the early 2000s, tech giants like Google, Amazon, and Yahoo faced data at a scale that traditional systems couldn‚Äôt handle. This led to the **Big Data movement**.\n",
    "\n",
    "Here‚Äôs what stood out:\n",
    "- **Big Data** was defined by the 3 V's: **Volume**, **Velocity**, and **Variety**.\n",
    "- In **2004**, Google released the **MapReduce** paper, which introduced a new way to process huge amounts of data.\n",
    "- In **2006**, Yahoo open-sourced **Apache Hadoop**, inspired by Google‚Äôs paper. This was a major shift ‚Äî suddenly, even small companies could work with massive datasets.\n",
    "- Around the same time, **Amazon Web Services (AWS)** launched services like **EC2**, **S3**, and **DynamoDB**, making cloud computing accessible to everyone.\n",
    "\n",
    "These developments created a new generation of **data engineers**, especially those focused on solving problems at scale.\n",
    "\n",
    "---\n",
    "\n",
    "## The 2010s: Cloud and Real-Time Data\n",
    "\n",
    "By the 2010s, public cloud platforms like **AWS, Google Cloud, and Azure** became mainstream. This made it much easier to manage and process data without setting up massive infrastructure.\n",
    "\n",
    "A big shift also happened from **batch processing** (processing data in chunks) to **real-time streaming**, where data could be processed as it arrived. Tools like **Apache Kafka** and **Apache Spark** helped with this transition.\n",
    "\n",
    "Eventually, the term **Big Data** faded because working with large-scale data became a common part of engineering. It wasn‚Äôt a ‚Äúspecial case‚Äù anymore ‚Äî just part of the job.\n",
    "\n",
    "---\n",
    "\n",
    "## Today: The Role of Modern Data Engineers\n",
    "\n",
    "Today, **data engineering** is a central and strategic part of any data-driven business. Data engineers now work with:\n",
    "- Cloud-native tools (like AWS Glue, Snowflake, Redshift)\n",
    "- Workflow orchestrators (like Airflow or Dagster)\n",
    "- Real-time data processing tools (like Kafka and Flink)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cec7e5",
   "metadata": {},
   "source": [
    "# Stakeholders in the Data Engineering Workflow\n",
    "\n",
    "In a data engineering workflow, the data engineer plays a central role ‚Äî acting as a bridge between upstream and downstream stakeholders.\n",
    "\n",
    "---\n",
    "\n",
    "## Downstream Stakeholders\n",
    "\n",
    "Downstream stakeholders are the consumers of processed and served data. These include:\n",
    "\n",
    "- **Analysts**\n",
    "- **Data Scientists**\n",
    "- **Machine Learning Engineers**\n",
    "- **Salespeople**\n",
    "- **Marketing Professionals**\n",
    "- **Executives**\n",
    "\n",
    "Each stakeholder group has different data needs, goals, and expectations.\n",
    "\n",
    "To serve downstream stakeholders effectively, the data engineer must understand:\n",
    "- **How often** data is needed (e.g., real-time vs daily)\n",
    "- **What information** is needed (specific tables, metrics, joins, aggregations)\n",
    "- **How much latency** is acceptable (seconds, hours, days)\n",
    "\n",
    "An example:  \n",
    "A business analyst may need to run SQL queries for dashboards and trend analysis. To support this, the data engineer must ensure:\n",
    "- Data is refreshed frequently enough\n",
    "- Queries run efficiently (through pre-aggregations or materialized views)\n",
    "- Time zones and definitions (like start/end of \"day\") are consistent and well-aligned\n",
    "\n",
    "---\n",
    "\n",
    "## Upstream Stakeholders\n",
    "\n",
    "Upstream stakeholders are the owners of source systems that generate raw data. Most often, these are **software engineers**, either within the organization or from external systems.\n",
    "\n",
    "From upstream stakeholders, the data engineer needs to understand:\n",
    "- **Data volume** (how much data to expect)\n",
    "- **Frequency** (how often data is emitted)\n",
    "- **Format** (JSON, CSV, Avro, etc.)\n",
    "- **Data security** and **compliance** considerations\n",
    "- **Schema changes**, system outages, or disruptions to the data flow\n",
    "\n",
    "In many ways, the data engineer becomes the **consumer** of upstream data, similar to how analysts consume the outputs produced by the data engineer.\n",
    "\n",
    "Establishing a strong communication loop with upstream teams can help anticipate changes and design resilient data pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Responsibilities\n",
    "\n",
    "The data engineer must:\n",
    "- Translate upstream raw data into usable, reliable formats\n",
    "- Serve that data to downstream users in a way that supports their specific goals\n",
    "- Maintain communication in both directions to ensure smooth data operations and system alignment\n",
    "\n",
    "---\n",
    "\n",
    "## Visual Summary\n",
    "\n",
    "![Data Engineering Stakeholders Diagram](image/workflow_data_engineering.png)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73925a5b",
   "metadata": {},
   "source": [
    "# Requirements Gathering for Data Engineering Systems\n",
    "\n",
    "Before building any data system ‚Äî writing code, provisioning infrastructure, or deploying to the Cloud ‚Äî it is critical to **understand stakeholder needs** and translate them into system requirements.\n",
    "\n",
    "---\n",
    "\n",
    "## Types of Requirements\n",
    "\n",
    "### 1. Business Requirements  \n",
    "These define the **high-level goals of the organization**, such as:\n",
    "- Increasing revenue\n",
    "- Growing user base\n",
    "- Improving customer experience\n",
    "\n",
    "### 2. Stakeholder Requirements  \n",
    "These are the **individual needs** of downstream stakeholders (analysts, data scientists, executives, etc.) ‚Äî the tasks they need data to help accomplish.\n",
    "\n",
    "### 3. System Requirements  \n",
    "System requirements define what the system must do to meet business and stakeholder needs. These are split into:\n",
    "\n",
    "- **Functional Requirements** (the **what**)  \n",
    "  - Example: \"Refresh the dashboard data every 24 hours\"\n",
    "  - Example: \"Send alerts when data anomalies are detected\"\n",
    "\n",
    "- **Non-Functional Requirements** (the **how**)  \n",
    "  - Example: \"Use a cloud-based ingestion system that supports real-time streaming\"\n",
    "  - Example: \"Ensure latency is under 2 minutes and uptime is 99.9%\"\n",
    "\n",
    "---\n",
    "\n",
    "## What to Consider in System Requirements\n",
    "\n",
    "- Business goals and stakeholder needs\n",
    "- Features and attributes of your data products\n",
    "- Compute, memory, and storage capacity\n",
    "- Data freshness and latency expectations\n",
    "- Security and regulatory compliance\n",
    "- Cost constraints\n",
    "\n",
    "---\n",
    "\n",
    "## The Process of Requirements Gathering\n",
    "\n",
    "Requirements gathering starts with **talking to stakeholders**. However, stakeholders rarely present their needs in the form of technical specifications. Instead, they express **business goals** or frustrations.\n",
    "\n",
    "It‚Äôs the data engineer‚Äôs responsibility to:\n",
    "- Ask the right questions\n",
    "- Translate ambiguous needs into clear system requirements\n",
    "- Tailor conversations based on the stakeholder's technical background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a977d",
   "metadata": {},
   "source": [
    "# Stakeholder Conversation: Data Engineer & Data Scientist\n",
    "\n",
    "This section summarizes a mock stakeholder conversation between Joe (Data Engineer) and Colleen (Data Scientist). The goal of the conversation is to gather requirements for a data system that supports marketing and product analytics.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objective\n",
    "\n",
    "To understand the challenges faced by the data scientist and translate them into **system requirements** that the data engineer can address through ingestion, transformation, and serving of data.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Key Problems Identified\n",
    "\n",
    "### 1. Limited and Manual Data Access\n",
    "- Sales data resides in a **production database**.\n",
    "- Colleen does not have direct access due to risks; receives **daily data dumps** instead.\n",
    "- Data is delivered in **CSV/JSON formats**.\n",
    "\n",
    "### 2. Dirty and Overwhelming Data\n",
    "- 90% of the data received is not useful.\n",
    "- Colleen spends **80% of her time** cleaning and preparing the data.\n",
    "- Scripts **frequently break** due to anomalies or schema changes.\n",
    "\n",
    "### 3. Outdated Data for Analytics\n",
    "- Marketing team wants **real-time** sales data by region.\n",
    "- Current dashboards show data that is **2 days old**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Current Use Cases\n",
    "\n",
    "### Dashboards for Marketing\n",
    "- Show 30-day sales trends by **product category** and **region**.\n",
    "- Support **drill-down** to hourly/product-level insights.\n",
    "- Require fresher data for **campaign timing and evaluation**.\n",
    "\n",
    "### Product Recommendation Engine\n",
    "- Currently based on **most popular products**.\n",
    "- Future goal: **personalized recommendations** using content-based filtering.\n",
    "- Needs:\n",
    "  - Real-time or recent **user behavior data**\n",
    "  - A way to **deploy and serve model outputs**\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Insights from the Conversation\n",
    "\n",
    "- Need to **automate** data ingestion and processing.\n",
    "- Requirement for **low-latency** data (exact threshold TBD).\n",
    "- Marketing may benefit from:\n",
    "  - Data updated **hourly or more frequently**\n",
    "  - Ability to **target campaigns** using fresh user data\n",
    "- Additional follow-up needed with marketing team to clarify:\n",
    "  - **Actionable use cases**\n",
    "  - **Required freshness/latency**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Initial System Requirements\n",
    "\n",
    "### Functional Requirements (What the system should do)\n",
    "- Ingest sales data more **frequently and automatically**\n",
    "- Transform and clean data to remove irrelevant parts\n",
    "- Serve aggregated, cleaned data to dashboards\n",
    "- Support training and deployment of **ML recommendation models**\n",
    "\n",
    "### Non-Functional Requirements (How the system should work)\n",
    "- Handle **schema changes gracefully**\n",
    "- Maintain **data freshness** suitable for near real-time needs\n",
    "- Be **resilient** and monitored for anomalies or failures\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Next Steps\n",
    "\n",
    "- Follow up with **marketing stakeholders** to refine data freshness and use case requirements.\n",
    "- Design a pipeline that supports:\n",
    "  - Reliable and automated **data ingestion**\n",
    "  - Scalable **data transformation and storage**\n",
    "  - Efficient **data serving** for both dashboards and ML use cases\n",
    "\n",
    "---\n",
    "\n",
    "This conversation highlights how initial stakeholder interviews are essential for uncovering not only technical needs but also organizational goals and pain points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86702a07",
   "metadata": {},
   "source": [
    "# Breaking Down a Stakeholder Conversation: Requirements Gathering\n",
    "\n",
    "In this section, we reflect on the mock conversation between the data engineer and the data scientist (Colleen) to extract actionable requirements and outline a reusable approach to stakeholder interviews in data engineering projects.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Purpose\n",
    "\n",
    "To demonstrate how to:\n",
    "- Extract system requirements from stakeholder conversations.\n",
    "- Clarify vague terminology like ‚Äúreal-time.‚Äù\n",
    "- Identify additional stakeholders to speak with.\n",
    "- Translate business needs into data engineering solutions.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Key Steps in Requirements Gathering\n",
    "\n",
    "### 1. Understand Existing Systems and Pain Points\n",
    "- Learn what systems are currently in place.\n",
    "- Identify inefficiencies, delays, manual steps, and risks.\n",
    "- In this case:\n",
    "  - Only daily data dumps from the production database.\n",
    "  - Data is messy and frequently breaks scripts due to schema changes.\n",
    "\n",
    "### 2. Ask What Actions Stakeholders Will Take with the Data\n",
    "- Don't just ask what data they want ‚Äî ask what decisions or operations they will perform.\n",
    "- Helps clarify how critical the data is and what latency is acceptable.\n",
    "- Example:\n",
    "  - Dashboards are used to optimize marketing campaigns.\n",
    "  - Recommendation engine is used to influence customer purchases during browsing.\n",
    "\n",
    "### 3. Confirm Your Understanding\n",
    "- Summarize and repeat back what you've heard.\n",
    "- Ensure alignment before building any solution.\n",
    "- In this case:\n",
    "  - Automating ingestion and transformation would be a huge help.\n",
    "  - Serving clean, near real-time data would improve dashboard and ML performance.\n",
    "\n",
    "### 4. Identify Other Stakeholders\n",
    "- Your current stakeholder may not have all the information.\n",
    "- Additional conversations are needed with:\n",
    "  - **Software Engineers** (who manage the source system)\n",
    "  - **Marketing Team** (to clarify what \"real-time\" means and what they‚Äôll do with the data)\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Requirements Identified\n",
    "\n",
    "### Functional Requirements (What the system should do)\n",
    "- Ingest data from the sales platform.\n",
    "- Transform and clean the data automatically.\n",
    "- Serve data to:\n",
    "  - Dashboards (marketing use case)\n",
    "  - Recommendation engine (ML use case)\n",
    "\n",
    "### Non-Functional Requirements (How the system should perform)\n",
    "- Define and meet latency thresholds (e.g., hourly vs real-time).\n",
    "- Handle schema changes without failure.\n",
    "- Ensure reliability and scalability of pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Important Tactic\n",
    "\n",
    "### Ask: ‚ÄúWhat action will you take based on the data?‚Äù\n",
    "- Avoid letting stakeholders define the system themselves.\n",
    "- Focus on understanding their **business use case** first.\n",
    "- Then derive the appropriate technical implementation.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaway:\n",
    "> The foundation of a successful data engineering project is built during **requirements gathering**, where listening, translating, and aligning business goals with technical execution is critical.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a169e5",
   "metadata": {},
   "source": [
    "# Thinking Like a Data Engineer\n",
    "\n",
    "In any data engineering project, success depends on more than just technical implementation. It starts with understanding the business context and ends with continuous iteration based on stakeholder needs. Below is a four-stage framework for thinking like a data engineer.\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Framework Overview\n",
    "\n",
    "This framework consists of four main stages:\n",
    "\n",
    "1. **Identify business goals & stakeholder needs**\n",
    "2. **Define system requirements**\n",
    "3. **Choose tools & technologies**\n",
    "4. **Build, evaluate, iterate & evolve**\n",
    "\n",
    "This is not a strict linear process ‚Äî in real-world scenarios, you'll often revisit earlier stages as goals and technologies evolve.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Stage 1: Identify Business Goals & Stakeholder Needs\n",
    "\n",
    "- Identify business goals and the stakeholders you are serving.\n",
    "- Explore existing systems and what pain points stakeholders currently face.\n",
    "- Ask stakeholders: **\"What actions will you take using the data product?\"**\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Stage 2: Define System Requirements\n",
    "\n",
    "- Translate stakeholder needs into **functional requirements** (what the system should do).\n",
    "- Define **non-functional requirements** (how the system should perform).\n",
    "- Document and confirm requirements with stakeholders to ensure alignment.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Stage 3: Choose Tools & Technologies\n",
    "\n",
    "- Identify tools and technologies that meet the non-functional requirements.\n",
    "- Conduct a **cost-benefit analysis** to compare different options.\n",
    "- **Prototype and test** your design to check if it meets stakeholder expectations.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Stage 4: Build, Evaluate, Iterate & Evolve\n",
    "\n",
    "- Build and deploy the **production-ready system**.\n",
    "- Continuously **monitor and evaluate** its performance.\n",
    "- Iterate and evolve the system based on feedback and changing needs.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Visual Summary\n",
    "![Thinking Like a Data Engineer](Introduction_to_Data_Engineering/Module1/image/framework.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239b43a",
   "metadata": {},
   "source": [
    "## üå©Ô∏è Introduction to Cloud Computing on AWS\n",
    "\n",
    "### What is the Cloud?\n",
    "\n",
    "At **AWS**, the cloud is described as:\n",
    "\n",
    "> **‚ÄúThe on-demand delivery of IT resources over the Internet with pay-as-you-go pricing.‚Äù**\n",
    "\n",
    "This means:\n",
    "- You get computing/storage/networking resources instantly, whenever needed.\n",
    "- You shut them down when not in use.\n",
    "- You only pay for what you use.\n",
    "\n",
    "This is very different from traditional on-premise setups, where you:\n",
    "- Purchase hardware up-front.\n",
    "- Commit to long-term investments.\n",
    "- Must manage capacity and scaling yourself.\n",
    "\n",
    "---\n",
    "\n",
    "### üß± Core AWS Resources\n",
    "\n",
    "These core resources are the **building blocks** of most cloud systems:\n",
    "\n",
    "#### 1. **Compute Resources**\n",
    "Places to run code:\n",
    "- Virtual Machines (e.g., EC2)\n",
    "- Container services (e.g., ECS, EKS)\n",
    "- Serverless functions (e.g., AWS Lambda)\n",
    "\n",
    "#### 2. **Storage Resources**\n",
    "Places to store data:\n",
    "- **Amazon S3** (object storage)\n",
    "- **Amazon EBS** (block storage)\n",
    "- **Databases** (RDS, DynamoDB, Neptune, etc.)\n",
    "\n",
    "#### 3. **Networking Resources**\n",
    "Connect services internally or to the Internet:\n",
    "- **Amazon VPC** ‚Äì Your own private network in the cloud.\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Benefits of Cloud Computing\n",
    "\n",
    "#### ‚úÖ **Scalable & Elastic**\n",
    "- You don't have to estimate or provision storage ahead of time.\n",
    "- AWS services like **S3** scale automatically.\n",
    "- You're always ready for traffic spikes or demand changes.\n",
    "\n",
    "#### ‚úÖ **Cost-Efficient**\n",
    "- No upfront investment.\n",
    "- Like electricity ‚Äî you only pay for what you use.\n",
    "\n",
    "---\n",
    "\n",
    "### üåç AWS Global Infrastructure\n",
    "\n",
    "AWS resources are not tied to a single data center. They are distributed across:\n",
    "\n",
    "#### üîπ **Regions**\n",
    "- A Region is a **geographic area** (e.g., `us-east-1`, `ap-south-1`).\n",
    "- Examples:  \n",
    "  - **US East (N. Virginia)**  \n",
    "  - **Asia Pacific (Mumbai)**  \n",
    "  - **Europe (Frankfurt)**\n",
    "\n",
    "#### üîπ **Availability Zones (AZs)**\n",
    "- Each region has **multiple AZs**, which are **isolated clusters of data centers**.\n",
    "- AZs are designed for **fault tolerance**:\n",
    "  - If one AZ fails (e.g., due to power outage or flood), the others handle the load.\n",
    "\n",
    "#### üõ†Ô∏è Region ‚Üí AZ ‚Üí Data Centers  \n",
    "\n",
    "Multiple Data Centers ‚Üí 1 AZ\n",
    "Multiple AZs ‚Üí 1 AWS Region\n",
    "\n",
    "---\n",
    "\n",
    "### üåê High-Speed Global Network\n",
    "\n",
    "AWS connects its AZs and data centers using:\n",
    "- A global network of **fiber cables**.\n",
    "- High-speed **low-latency** connections.\n",
    "- This helps services stay **available**, **reliable**, and **fast**.\n",
    "\n",
    "---\n",
    "\n",
    "### üß© Combining Services as a Data Engineer\n",
    "\n",
    "As a data engineer, you‚Äôll:\n",
    "- Combine multiple AWS services like building blocks.\n",
    "- Build solutions for **data ingestion**, **transformation**, **orchestration**, and **analytics**.\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b773716",
   "metadata": {},
   "source": [
    "# ‚òÅÔ∏è Introduction to AWS Core Services & Concepts\n",
    "\n",
    "## üåê What is the AWS Cloud?\n",
    "\n",
    "- **AWS** is the on-demand delivery of IT resources over the internet with **pay-as-you-go pricing**.\n",
    "- No upfront cost, no need to manage physical servers.\n",
    "- You only pay for what you use ‚Äî like electricity.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Core Categories of AWS Services\n",
    "\n",
    "We will break this down into 5 major categories:\n",
    "\n",
    "1. **Compute**\n",
    "2. **Networking**\n",
    "3. **Storage**\n",
    "4. **Databases**\n",
    "5. **Security**\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è 1. Compute ‚Äì *Processing Power*\n",
    "\n",
    "- **Amazon EC2 (Elastic Compute Cloud):**  \n",
    "  Virtual machines (VMs) in the cloud where you can run your code, host applications, or build pipelines.\n",
    "\n",
    "  - You can choose OS (Linux/Windows), storage, CPU/RAM specs.\n",
    "  - You have **full control** over the environment.\n",
    "  - You can **scale horizontally** by launching many EC2 instances.\n",
    "\n",
    "- **AWS Lambda:**  \n",
    "  A serverless service to run code in response to events. You **don‚Äôt manage servers** at all.\n",
    "\n",
    "- **Amazon ECS / EKS:**  \n",
    "  Managed services to run **containers** (Docker/Kubernetes).\n",
    "\n",
    "---\n",
    "\n",
    "### üåê 2. Networking ‚Äì *Connectivity & Isolation*\n",
    "\n",
    "- **Amazon VPC (Virtual Private Cloud):**  \n",
    "  A private network inside AWS where your resources (like EC2s, RDS) reside.\n",
    "\n",
    "  - You control subnets, IP addresses, routing.\n",
    "  - Ensures **secure and isolated networking**.\n",
    "  - All resources like EC2, RDS, Redshift are launched **inside a VPC**.\n",
    "\n",
    "- VPC spans across **Availability Zones (AZs)** inside a **Region**.\n",
    "\n",
    "---\n",
    "\n",
    "### üíæ 3. Storage ‚Äì *Saving Data*\n",
    "\n",
    "- **Amazon S3 (Simple Storage Service):**\n",
    "  - Object storage for **any kind of file or unstructured data**.\n",
    "  - Use it for storing logs, images, videos, documents, etc.\n",
    "  - Automatically scales and is highly durable and elastic.\n",
    "\n",
    "- **Amazon EBS (Elastic Block Store):**\n",
    "  - Block storage used as **disks attached to EC2 instances**.\n",
    "  - High performance, low latency.\n",
    "\n",
    "- **Amazon EFS (Elastic File System):**\n",
    "  - Managed file system that can be **shared across multiple EC2s**.\n",
    "  - Works like your laptop file system (hierarchical).\n",
    "\n",
    "---\n",
    "\n",
    "### üóÉÔ∏è 4. Databases ‚Äì *Structured Data*\n",
    "\n",
    "- **Amazon RDS (Relational Database Service):**\n",
    "  - Fully managed relational databases (MySQL, PostgreSQL, etc.).\n",
    "  - Easy to scale, secure, and backup.\n",
    "\n",
    "- **Amazon Redshift:**\n",
    "  - A **data warehouse** built for analytics.\n",
    "  - Used for running **complex queries on large datasets** quickly.\n",
    "  - Ideal for **business intelligence (BI)** and **dashboards**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîê 5. Security ‚Äì *Keeping Everything Safe*\n",
    "\n",
    "- **Shared Responsibility Model:**\n",
    "  - AWS secures the cloud (hardware, data centers, virtualization).\n",
    "  - **You secure what you build inside the cloud** (your data, your code, your configurations).\n",
    "\n",
    "  üìå *Analogy:*  \n",
    "  Think of AWS like an apartment building.  \n",
    "  - AWS ensures the building is secure.\n",
    "  - You must lock your own door and protect your own apartment.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† What is an Instance in Cloud?\n",
    "\n",
    "> A **cloud instance** is a **virtual machine** (VM) that runs on hardware managed by the cloud provider.\n",
    "\n",
    "### üß∞ Features of a Cloud Instance:\n",
    "- Acts like a **remote computer**\n",
    "- You can:\n",
    "  - Install OS (Linux/Windows)\n",
    "  - Run code and scripts\n",
    "  - Host applications\n",
    "- Fully configurable and scalable\n",
    "- Can be started, stopped, or terminated anytime\n",
    "\n",
    "### üîÅ Analogy:\n",
    "> A cloud **instance** is like renting a room in a hotel.  \n",
    "You don‚Äôt own the hotel (cloud servers), but you get **full access** to your own private room (VM).\n",
    "\n",
    "### ‚úÖ Real Use Case:\n",
    "- A data engineer can use **EC2 instances** to:\n",
    "  - Write Python code\n",
    "  - Ingest data from APIs or S3\n",
    "  - Process data and store the result in **Redshift** or **RDS**\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Quick Clarification\n",
    "\n",
    "- ‚úÖ S3 is **object storage**, ideal for storing files long-term (but not for querying directly).\n",
    "- ‚úÖ Redshift is a **data warehouse**, optimized for **fast querying**, but it's still persistent.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6395e7f6",
   "metadata": {},
   "source": [
    "# ‚òÅÔ∏è Compute ‚Äì Amazon Elastic Compute Cloud (EC2)\n",
    "\n",
    "## What is EC2?\n",
    "\n",
    "- Amazon EC2 (Elastic Compute Cloud) is a **virtual server** (or **virtual machine**) in the cloud.\n",
    "- Lets you **run applications, code, or pipelines** on a machine you can configure (OS, CPU, memory).\n",
    "- Highly **scalable, elastic, and pay-as-you-go**.\n",
    "\n",
    "## What is a Server vs Virtual Server?\n",
    "\n",
    "| Concept             | Physical Server                             | Virtual Server (VM)                              |\n",
    "|---------------------|---------------------------------------------|--------------------------------------------------|\n",
    "| Hardware            | Real CPU, RAM, Storage                      | Emulated (software-based) hardware               |\n",
    "| OS & Applications   | Installed directly on machine               | Installed on top of virtualized environment      |\n",
    "| Flexibility         | Limited by physical resources               | Scales as needed using shared resources          |\n",
    "\n",
    "## üß† What is a Hypervisor?\n",
    "\n",
    "- A **Hypervisor** is software that allows multiple virtual machines to run on a single physical machine.\n",
    "- It **distributes CPU, memory, and disk** among different VMs.\n",
    "- Acts as a **bridge between physical hardware and VMs**.\n",
    "\n",
    "## üß± Components of a Virtual Machine\n",
    "\n",
    "- **Virtual hardware** (emulated CPU, memory, etc.)\n",
    "- **Operating System** (Linux, Windows, etc.)\n",
    "- **Applications** (your code or services)\n",
    "\n",
    "## üí° Why Virtualization?\n",
    "\n",
    "- Efficient use of underlying hardware.\n",
    "- Multiple VMs share the same physical machine.\n",
    "- Reduces cost and improves scalability.\n",
    "\n",
    "\n",
    "![rs_Vs_vs](introduction_to_Data_Engineering/Module1/image/rs_vs_vs.png)\n",
    "---\n",
    "\n",
    "## üìè EC2 Instance Types and Pricing\n",
    "\n",
    "- **Instance Types**:\n",
    "  - **General Purpose** (e.g., t3)\n",
    "  - **Compute Optimized** (e.g., c5)\n",
    "  - **Memory Optimized** (e.g., r5)\n",
    "  - **Storage Optimized** (e.g., i3)\n",
    "  - **Accelerated Computing** (e.g., p3)\n",
    "\n",
    "- **Naming Example**: `t3a.micro`\n",
    "  - `t` = instance family\n",
    "  - `3` = generation\n",
    "  - `a` = optional capabilities (e.g., AMD-based)\n",
    "  - `micro` = instance size\n",
    "\n",
    "### üí∞ EC2 Pricing Options\n",
    "\n",
    "- **On-Demand**: No long-term commitments. Pay per hour or second.\n",
    "- **Spot Instances**: Use spare AWS capacity at lower cost.\n",
    "- **Reserved Instances**: Commit to 1 or 3 years for heavy workloads.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "- EC2 is like a **cloud-based computer** where you run pipelines or services.\n",
    "- You can **scale vertically (size)** or **horizontally (add more instances)**.\n",
    "- It connects with tools like **S3, Redshift**, and operates inside a **VPC** (Virtual Private Cloud).\n",
    "- You control everything inside the instance (OS, apps, firewall, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe715f",
   "metadata": {},
   "source": [
    "# üåê Networking ‚Äì VPC and Subnets\n",
    "\n",
    "## üß± What is a VPC (Virtual Private Cloud)?\n",
    "\n",
    "A **VPC** is an isolated private network where you can launch your AWS resources.\n",
    "\n",
    "- Exists **within a region**, and spans **multiple availability zones**.\n",
    "- Helps isolate and **secure your EC2 instances, databases**, and more.\n",
    "- Think of it as a **private floor in an office building** just for your team.\n",
    "\n",
    "### üîê Analogy\n",
    "\n",
    "Imagine an **office building** (the AWS Region). Your company rents an **entire private floor** (VPC).  \n",
    "You install security doors, choose who gets access, and control whether rooms connect to the internet.\n",
    "\n",
    "### üí° Real Example\n",
    "\n",
    "- You launch EC2 instances in a VPC.\n",
    "- Unless you configure internet access, they're **not reachable from the outside**.\n",
    "- You can add Internet Gateways or NAT Gateways to allow selected traffic.\n",
    "\n",
    "---\n",
    "\n",
    "## ü™ü What is a Subnet?\n",
    "\n",
    "A **subnet** is a smaller network within your VPC ‚Äî a **room inside your floor**.\n",
    "\n",
    "- Can be **public** (accessible from internet) or **private** (no internet).\n",
    "- Helps you group resources by **function** and **access level**.\n",
    "- Each subnet exists in **one availability zone**.\n",
    "\n",
    "### üîê Analogy\n",
    "\n",
    "On your private office floor (VPC):\n",
    "- Some rooms (subnets) like the **reception area** are open to visitors (public).\n",
    "- Others like the **finance room** are locked and accessible only internally (private).\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Use Case: Web App Deployment\n",
    "\n",
    "| Component         | Placement        | Notes                                               |\n",
    "|------------------|------------------|-----------------------------------------------------|\n",
    "| Web Server (EC2) | Public Subnet     | Accepts user requests via the internet              |\n",
    "| Database (RDS)   | Private Subnet    | Not internet-facing; only web server can access it  |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Summary\n",
    "\n",
    "- **VPC** = your private network on AWS\n",
    "- **Subnet** = slices of that network for public/private access\n",
    "- VPCs ensure **isolation**, **security**, and **control** over cloud networking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cb8894",
   "metadata": {},
   "source": [
    "# Security - AWS Shared Responsibility Model\n",
    "\n",
    "When you host your applications and resources in the cloud, you‚Äôre offloading the heavy duty of managing the physical hardware to the cloud provider. The **security of the physical facility** is the **responsibility of the cloud provider**. However, you **still own your data in AWS**, and **you are responsible for managing its security**. This is known as the **Shared Responsibility Model** on AWS.\n",
    "\n",
    "---\n",
    "\n",
    "## üîí AWS is responsible for **security of the cloud**\n",
    "\n",
    "This includes:\n",
    "\n",
    "- Maintaining, protecting, and securing the **physical facilities** (data centers).\n",
    "- Securing the **global infrastructure**:\n",
    "  - Fiber optic cables connecting regions\n",
    "  - Software and hardware running AWS services\n",
    "\n",
    "---\n",
    "\n",
    "## üîê You are responsible for **security in the cloud**\n",
    "\n",
    "This includes:\n",
    "\n",
    "- **Protecting your data** (at rest and in transit)\n",
    "- Managing **who can access the data**\n",
    "- Configuring **access control** (IAM roles, policies, encryption)\n",
    "- Setting up **networking rules** (like VPC security groups and firewall rules)\n",
    "- Ensuring **proper configurations** for the services you use\n",
    "\n",
    "> üß† **Note**: Your responsibilities depend on the services you choose. For example, EC2 requires managing the operating system and patching, whereas services like S3 or Lambda have fewer responsibilities.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Why it matters\n",
    "\n",
    "It‚Äôs essential to understand and apply the Shared Responsibility Model because:\n",
    "\n",
    "- You **control access** to the data you store in the cloud\n",
    "- You are accountable for **securing pipelines** and workloads\n",
    "- Misconfiguration on your part can lead to **security breaches**\n",
    "\n",
    "---\n",
    "\n",
    "### üè¢ Analogy: Apartment Building\n",
    "\n",
    "| AWS                        | You                               |\n",
    "|---------------------------|------------------------------------|\n",
    "| Maintains the building     | Locks your door                    |\n",
    "| Ensures elevators work     | Keeps your valuables safe          |\n",
    "| Protects wiring & plumbing | Grants access to guests (or not!)  |\n",
    "\n",
    "Both parties need to do their part to ensure full security üîê."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
