{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6a10c5",
   "metadata": {},
   "source": [
    "# üìå Building a Data Pipeline: Requirements Gathering and System Design\n",
    "\n",
    "---\n",
    "\n",
    "## üß± Hierarchy of Needs\n",
    "\n",
    "To design a reliable and effective data pipeline, it is important to understand the hierarchy of needs, starting from business goals to system requirements.\n",
    "![hierarchy of needs](./images/hierarchy_of_needs.png)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Business Goals (CTO Conversation)\n",
    "\n",
    "The CTO shared high-level priorities for the company:\n",
    "\n",
    "- Expanding market share through new product offerings and international expansion\n",
    "- Refactoring legacy systems to avoid outages\n",
    "- Transitioning from batch-based systems to streaming architectures (Kinesis/Kafka)\n",
    "- Improving customer retention with a personalized recommendation engine\n",
    "- Minimizing the software‚Äìdata divide by ensuring data is generated in an analytics-ready schema\n",
    "\n",
    "---\n",
    "\n",
    "## üë• Stakeholder Needs\n",
    "\n",
    "### üîΩ Downstream Stakeholders ‚Äì Marketing Team & Data Scientists\n",
    "\n",
    "**Dashboards:**\n",
    "- Current dashboards show data with a 2-day delay.\n",
    "- The marketing team needs access to near real-time data (within 1 hour) to act on trending products.\n",
    "- Quick action is required to launch region-specific campaigns during sales spikes that last a few hours.\n",
    "\n",
    "**Recommendation System:**\n",
    "- Currently built on weekly popular products for all users.\n",
    "- Needs to shift toward personalized recommendations based on individual user history and cart behavior.\n",
    "\n",
    "---\n",
    "\n",
    "### üìÑ Functional Requirements\n",
    "\n",
    "#### üìä Dashboards\n",
    "\n",
    "- Process and deliver product sales data with no more than 1-hour delay.\n",
    "- Enable filtering by region, category, product, and time (down to hourly granularity).\n",
    "\n",
    "![Dashboard Functional Requirements](./images/functional_requirements_dashboard.png)\n",
    "\n",
    "#### ü§ñ Recommendation System\n",
    "\n",
    "- Ingest user activity and purchase behavior.\n",
    "- Serve personalized product recommendations in real time or near real time.\n",
    "\n",
    "![Recommender Functional Requirements](./images/functional_requirements_recommender.png)\n",
    "\n",
    "---\n",
    "\n",
    "### üîº Upstream Stakeholder ‚Äì Software Engineer (Source System Owner)\n",
    "\n",
    "**Challenges Identified:**\n",
    "- Direct access to the production database is restricted for safety.\n",
    "- Data is shared via downloadable files (daily exports), leading to delays.\n",
    "- Schema changes occur frequently due to new feature rollouts and regional expansions.\n",
    "- Read replicas and APIs are proposed as alternatives for safer, real-time data access.\n",
    "- Data delivery may be affected by server outages or maintenance tasks.\n",
    "- Schema change notifications can be shared one week in advance.\n",
    "\n",
    "---\n",
    "\n",
    "## üìÑ Non-Functional Requirements\n",
    "\n",
    "#### üìä Dashboards\n",
    "\n",
    "- Low-latency data delivery (<1 hour)\n",
    "- Scalable to high volume spikes\n",
    "- Automatic schema validation and data quality checks\n",
    "- Fault tolerance and graceful fallback\n",
    "\n",
    "![Dashboard Non-Functional Requirements](./images/non_functional_dashboard.png)\n",
    "\n",
    "#### ü§ñ Recommendation System\n",
    "\n",
    "- <1 second response time for recommendation queries\n",
    "- Reliable ingestion of customer activity streams\n",
    "- Support for both batch (training) and streaming (serving) workflows\n",
    "- Scalable under increasing user load\n",
    "\n",
    "![Recommender Non-Functional Requirements](./images/non_functional_recommender.png)\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ System Design Summary\n",
    "\n",
    "Business goals were clarified through discussion with the CTO. Stakeholder needs were gathered from the marketing team and data scientists. Functional and non-functional requirements were documented based on these conversations. Constraints and upstream realities were confirmed through a conversation with the software engineer, leading to a plan for implementing a resilient, real-time data pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è Iron Triangle Consideration\n",
    "\n",
    "Design decisions must consider the trade-offs in the **Iron Triangle** of software:\n",
    "\n",
    "- **Fast**\n",
    "- **Cheap**\n",
    "- **Good**\n",
    "\n",
    "Only two of the three can be fully optimized at once.\n",
    "\n",
    "![Iron Triangle](./images/iron_triangle.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37bc476",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Batch ETL Services on AWS\n",
    "\n",
    "This section compares **AWS Glue** and **Amazon EMR**, two key services used for **batch data processing** and ETL workflows.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† What is AWS Glue?\n",
    "\n",
    "**AWS Glue** is a **fully managed, serverless ETL service** designed for structured and semi-structured data. It is ideal when you want to build pipelines **quickly** without managing infrastructure.\n",
    "\n",
    "### üîß Key Features\n",
    "\n",
    "- **Serverless**: No need to manage compute clusters.\n",
    "- **Built-in Crawlers**: Automatically infer schema and build data catalog.\n",
    "- **Jobs in Python or Scala** using Apache Spark under the hood.\n",
    "- **AWS Glue Studio**: No-code/low-code visual interface for ETL.\n",
    "- **Supports S3, RDS, Redshift, DynamoDB, and JDBC sources**.\n",
    "- **Max vCPUs per job**: ~100 vCPUs (approx.)\n",
    "- **Max memory per job**: ~1600 GB (combined)\n",
    "- **Max parallel job runs (per region)**: 10,000+\n",
    "- **Best for**: Up to **1‚Äì10 TB** of data per job.\n",
    "\n",
    "### üí° When to Use AWS Glue\n",
    "\n",
    "| Use Case                                     | Recommended? |\n",
    "|---------------------------------------------|--------------|\n",
    "| Schema inference & data cataloging          | ‚úÖ Yes        |\n",
    "| Serverless, fully managed ETL               | ‚úÖ Yes        |\n",
    "| 1‚Äì10 TB batch jobs                          | ‚úÖ Yes        |\n",
    "| No infra to manage                          | ‚úÖ Yes        |\n",
    "| Fine-tuned job performance                  | ‚ùå No         |\n",
    "\n",
    "---\n",
    "\n",
    "## üèóÔ∏è What is Amazon EMR?\n",
    "\n",
    "**Amazon EMR** (Elastic MapReduce) is a **managed big data platform** that allows you to **provision clusters** for frameworks like **Apache Spark, Hadoop, Hive, Presto, HBase**, etc.\n",
    "\n",
    "### üîß Key Features\n",
    "\n",
    "- **You manage the cluster** size and configuration.\n",
    "- **Fine-grained control** over nodes, memory, CPU, autoscaling, and pricing.\n",
    "- **Pay only for what you use**, but must manage jobs and infra.\n",
    "- **Use Spot, On-Demand, or Reserved EC2 instances.**\n",
    "- **Integrates with S3, HDFS, Hive Metastore, etc.**\n",
    "- **Max vCPUs per cluster**: Thousands (scalable by instance type)\n",
    "- **Max memory per cluster**: Several TBs (based on EC2 instance types)\n",
    "- **Best for**: **10 TB to Petabyte-scale** processing.\n",
    "\n",
    "### üí° When to Use Amazon EMR\n",
    "\n",
    "| Use Case                                     | Recommended? |\n",
    "|---------------------------------------------|--------------|\n",
    "| Fine-tuned Spark/Hadoop workloads            | ‚úÖ Yes        |\n",
    "| Petabyte-scale ETL                          | ‚úÖ Yes        |\n",
    "| Control over compute and cost optimization  | ‚úÖ Yes        |\n",
    "| Need fully serverless experience            | ‚ùå No         |\n",
    "| Small batch jobs with fast setup            | ‚ùå No         |\n",
    "\n",
    "---\n",
    "\n",
    "## üîç AWS Glue vs Amazon EMR ‚Äî Comparison Table\n",
    "\n",
    "| Feature                     | AWS Glue                              | Amazon EMR                          |\n",
    "|----------------------------|----------------------------------------|-------------------------------------|\n",
    "| **Type**                   | Serverless ETL                         | Managed Cluster-based ETL          |\n",
    "| **Management**             | Fully Managed                          | You manage cluster lifecycle       |\n",
    "| **Code Support**           | Python, Scala (via Spark)              | Spark, Hadoop, Hive, Presto, etc.  |\n",
    "| **Infra Control**          | ‚ùå No                                   | ‚úÖ Yes                              |\n",
    "| **Startup Time**           | ‚è±Ô∏è 2‚Äì5 minutes                         | ‚öôÔ∏è 5‚Äì15 minutes                    |\n",
    "| **Data Volume**            | ‚úÖ 1‚Äì10 TB                              | ‚úÖ 10 TB ‚Äì Petabytes               |\n",
    "| **Use with S3**            | ‚úÖ Native integration                   | ‚úÖ Native integration              |\n",
    "| **Autoscaling**            | ‚úÖ Handled by AWS                       | ‚úÖ Custom with EMR Auto Scaling   |\n",
    "| **Cost Visibility**        | Moderate                               | High control                       |\n",
    "| **Cost Estimation**        | ~$0.44 per DPU-hour                    | Based on EC2, EBS, EMR usage       |\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Final Takeaways\n",
    "\n",
    "- Use **AWS Glue** if:\n",
    "  - You want **quick setup**, **no cluster management**, and **1‚Äì10 TB** of ETL per job.\n",
    "  - You prefer a **code-free or low-code** ETL with crawlers and jobs.\n",
    "\n",
    "- Use **Amazon EMR** if:\n",
    "  - You need **full control** over compute/storage.\n",
    "  - Your workloads exceed **10 TB**, or require **fine-tuning**, **custom clusters**, or **frameworks** like Hive or Presto.\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Resources\n",
    "- [Coursera](https://www.coursera.org/learn/intro-to-data-engineering/supplement/f0PVn/aws-services-to-meet-your-requirements)\n",
    "- [AWS Glue Docs](https://docs.aws.amazon.com/glue/)\n",
    "- [Amazon EMR Docs](https://docs.aws.amazon.com/emr/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91daa1bc",
   "metadata": {},
   "source": [
    "# üß† AWS Batch Storage & Warehousing Services\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Amazon S3 (Simple Storage Service)\n",
    "\n",
    "### ‚úÖ What is Amazon S3?\n",
    "\n",
    "Amazon S3 is a **scalable object storage service** used to store and retrieve **any amount of data**, at **any time**, from anywhere on the web.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Key Features\n",
    "\n",
    "- **Unlimited storage** (practically)\n",
    "- Stores data as **objects** in **buckets**\n",
    "- Supports a wide variety of file types (CSV, JSON, Parquet, images, videos, etc.)\n",
    "- Low cost: **starts from $0.023 per GB/month**\n",
    "- **Highly durable**: 99.999999999% (11 9‚Äôs) durability\n",
    "- **Fine-grained access control** via IAM and bucket policies\n",
    "- **Lifecycle policies** to transition data to colder storage (Glacier, Deep Archive)\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Use Case Fit\n",
    "\n",
    "| Scenario                          | Suitability    |\n",
    "|----------------------------------|----------------|\n",
    "| Raw data lake                    | ‚úÖ Excellent    |\n",
    "| Storing unstructured data        | ‚úÖ Excellent    |\n",
    "| Long-term archival               | ‚úÖ Excellent    |\n",
    "| Querying via Athena              | ‚úÖ Good         |\n",
    "| Complex analytics (joins, OLAP) | ‚ùå Not suitable |\n",
    "\n",
    "---\n",
    "\n",
    "### üí¨ Simple Definition\n",
    "\n",
    "> Amazon S3 is like your data lake or cold storage ‚Äî great for storing lots of raw or unstructured data cheaply and reliably.\n",
    "\n",
    "---\n",
    "\n",
    "### ü§ñ ML & Analytics Perspective\n",
    "\n",
    "- Ideal for storing **large volumes of unstructured or semi-structured data**\n",
    "- Frequently used as the **source for training machine learning models** in batches\n",
    "- Common pattern: **store training data in S3 ‚Üí load into notebook or model pipeline**\n",
    "- Works well with Glue, SageMaker, and EMR\n",
    "\n",
    "---\n",
    "\n",
    "## üè¢ Amazon Redshift\n",
    "\n",
    "### ‚úÖ What is Amazon Redshift?\n",
    "\n",
    "Amazon Redshift is a **fully managed cloud data warehouse** designed for **analytical queries (OLAP)** on structured data.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Key Features\n",
    "\n",
    "- Columnar storage format for faster analytics\n",
    "- MPP (Massively Parallel Processing) architecture\n",
    "- Integrated with S3, Glue, Kinesis, SageMaker\n",
    "- **Fast performance**: optimized for complex SQL joins and aggregations\n",
    "- **Scalable**: up to petabytes of data\n",
    "- Cost: starts at **$0.25 per hour per node**, or ~$180/month for 1 DC2.large node\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Use Case Fit\n",
    "\n",
    "| Scenario                          | Suitability    |\n",
    "|----------------------------------|----------------|\n",
    "| BI dashboards                    | ‚úÖ Excellent    |\n",
    "| Large-scale SQL analytics        | ‚úÖ Excellent    |\n",
    "| Complex joins, aggregations      | ‚úÖ Excellent    |\n",
    "| Real-time streaming (insert-heavy) | ‚ùå Not ideal  |\n",
    "| Storing images, files, raw logs  | ‚ùå Not suitable |\n",
    "\n",
    "---\n",
    "\n",
    "### üí¨ Simple Definition\n",
    "\n",
    "> Amazon Redshift is like a high-performance, SQL-powered warehouse for crunching large volumes of clean, structured data quickly.\n",
    "\n",
    "---\n",
    "\n",
    "### ü§ñ ML & Analytics Perspective\n",
    "\n",
    "- **Ideal for feature engineering and batch model training**\n",
    "- Can **query terabytes of structured data** in seconds to prepare ML datasets\n",
    "- Often used after data is cleaned/transformed in Glue or stored in S3\n",
    "- You can export features from Redshift directly into **SageMaker** or other ML platforms\n",
    "\n",
    "---\n",
    "\n",
    "## üÜö S3 vs Redshift: When to Use What?\n",
    "\n",
    "| Feature                  | Amazon S3                        | Amazon Redshift                    |\n",
    "|--------------------------|----------------------------------|------------------------------------|\n",
    "| Storage Type             | Object storage                   | Columnar, relational database      |\n",
    "| Use Case                 | Raw/unstructured data lake       | Structured, analytical workloads   |\n",
    "| Query Engine             | Athena, EMR, Glue                | Native SQL engine (Redshift SQL)   |\n",
    "| Scalability              | Virtually unlimited              | Up to petabytes                    |\n",
    "| Pricing (est.)           | ~$23/TB/month                    | ~$180/month/node (DC2.large)       |\n",
    "| Durability               | 11 9s (99.999999999%)            | 99.9%                              |\n",
    "| Typical Query Volume     | Moderate (via Athena)            | High-volume, analytical queries    |\n",
    "| Setup Complexity         | Very low                         | Moderate (needs schema, tuning)    |\n",
    "| Latency (Read/Query)     | ~100‚Äì300 ms (S3 GET latency)     | ~1‚Äì2 sec for analytical queries on large datasets |\n",
    "\n",
    "> üìù Note:\n",
    "> - Redshift latency can drop to **~100‚Äì300 ms** for small queries and increase to **3‚Äì5 sec**+ for complex aggregations.\n",
    "> - S3 is not designed for direct querying, but with Athena, you can expect **~2‚Äì5 sec** per query on large datasets.\n",
    "> - Athena is a serverless query service that lets you run SQL queries directly on data stored in Amazon S3, without needing to load that data into a warehouse like Redshift.\n",
    "---\n",
    "\n",
    "## üß∞ Common Patterns\n",
    "\n",
    "- **Store raw data in S3**, clean/transform with Glue or EMR\n",
    "- **Load clean data into Redshift** for advanced analytics and ML\n",
    "- Use **Athena** to query S3 directly for ad-hoc SQL exploration\n",
    "- Export features from Redshift into **ML pipelines** or BI dashboards\n",
    "\n",
    "---\n",
    "\n",
    "## üìé Resources\n",
    "- [Coursera](https://www.coursera.org/learn/intro-to-data-engineering/supplement/f0PVn/aws-services-to-meet-your-requirements)\n",
    "- [Amazon S3 Docs](https://aws.amazon.com/s3/)\n",
    "- [Amazon Redshift Docs](https://aws.amazon.com/redshift/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b1ea2c",
   "metadata": {},
   "source": [
    "# üöÄ AWS Streaming Services: Kinesis, Firehose & MSK\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ What is Amazon Kinesis?\n",
    "\n",
    "**Amazon Kinesis** is a suite of services for real-time data streaming at scale. It allows you to ingest, process, and analyze data as it arrives.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Components of Kinesis\n",
    "\n",
    "| Service               | Description                                                                 |\n",
    "|-----------------------|-----------------------------------------------------------------------------|\n",
    "| **Kinesis Data Streams** | Real-time stream processing service (low-level).                             |\n",
    "| **Kinesis Data Firehose** | Fully managed service to load streaming data to destinations like S3, Redshift. |\n",
    "| **Kinesis Data Analytics** | Run SQL queries directly on streaming data.                                 |\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ What is Amazon Kinesis Data Streams?\n",
    "\n",
    "### ‚úÖ Key Concepts\n",
    "\n",
    "- **Shard**: A unit of capacity.  \n",
    "  - 1 shard = **1 MB/sec input** and **2 MB/sec output**\n",
    "  - Each shard supports up to **1,000 PUT records/sec**\n",
    "- **Buffer**: Temporary storage of records before processing or delivery\n",
    "- **Data Retention**: Time the stream stores data (default: 24 hours, max: 7 days)\n",
    "\n",
    "---\n",
    "\n",
    "### üß† How It Works\n",
    "\n",
    "- Producers send data to **Kinesis Stream**\n",
    "- Consumers (like Lambda, EMR, Glue) read data from the stream\n",
    "- Use cases: real-time dashboards, anomaly detection, log aggregation\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ ETL with Kinesis\n",
    "\n",
    "- **You need an ETL service** like:\n",
    "  - **AWS Glue**: For complex data transformation and cataloging\n",
    "  - **AWS Lambda**: For lightweight real-time processing\n",
    "  - **Amazon EMR**: For large-scale Spark/MapReduce jobs\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ What is Amazon Kinesis Data Firehose?\n",
    "\n",
    "A **fully managed, no-code option** for streaming data delivery.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Key Features\n",
    "\n",
    "- **No shard management** or provisioning\n",
    "- **Automatic batching**, compression, and encryption\n",
    "- **Delivers data** to:\n",
    "  - Amazon S3\n",
    "  - Amazon Redshift\n",
    "  - Amazon OpenSearch\n",
    "  - HTTP endpoints\n",
    "\n",
    "---\n",
    "\n",
    "### üß† How It Works\n",
    "\n",
    "1. You send streaming data to Firehose.\n",
    "2. It buffers and transforms data (if needed).\n",
    "3. Then delivers to destination ‚Äî no code required.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Firehose Buffer Size\n",
    "\n",
    "- Buffer by **size** (1‚Äì128 MB) or **time** (60‚Äì900 seconds)\n",
    "- Example: If buffer is 5MB or 60 seconds, it delivers whichever comes first.\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ What is Amazon MSK (Managed Streaming for Apache Kafka)?\n",
    "\n",
    "**MSK** is a **fully managed Apache Kafka** service.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Why Use MSK?\n",
    "\n",
    "- Use **Kafka APIs** if you're already familiar with Kafka\n",
    "- Suitable for **complex event-driven architectures**\n",
    "- Offers more **customization and flexibility** than Kinesis\n",
    "\n",
    "---\n",
    "\n",
    "### üîß MSK vs. Kinesis\n",
    "\n",
    "| Feature             | Kinesis                            | MSK (Kafka)                          |\n",
    "|---------------------|------------------------------------|--------------------------------------|\n",
    "| API Compatibility   | AWS proprietary                    | Apache Kafka APIs                    |\n",
    "| Setup               | Easy (fully managed by AWS)        | More setup required (but managed)    |\n",
    "| Ecosystem           | AWS-native integrations            | Huge open-source ecosystem           |\n",
    "| Cost                | Lower for small workloads          | More control, but potentially costlier|\n",
    "| Use Case Examples   | Simple ingestion, log streaming    | Complex pipelines, microservices     |\n",
    "\n",
    "---\n",
    "\n",
    "## üîÄ When to Use What?\n",
    "\n",
    "| Use Case                                      | Recommended Service        |\n",
    "|-----------------------------------------------|-----------------------------|\n",
    "| Real-time ingestion with AWS services         | Kinesis Data Streams        |\n",
    "| Serverless streaming to destinations          | Kinesis Firehose            |\n",
    "| Real-time SQL on streams                      | Kinesis Data Analytics      |\n",
    "| Apache Kafka compatibility required           | Amazon MSK                  |\n",
    "| Complex data transformation                   | Kinesis + Glue or EMR       |\n",
    "| Minimal config + auto delivery                | Firehose                    |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Architecture Example (Kinesis Firehose + Glue)\n",
    "\n",
    "1. Stream raw logs from web app into **Kinesis Firehose**\n",
    "2. Firehose buffers & sends to **S3**\n",
    "3. **AWS Glue** picks up from S3 ‚Üí transforms ‚Üí stores in **Redshift**\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Notes\n",
    "\n",
    "- All these services integrate well with **CloudWatch** for monitoring.\n",
    "- You can trigger **Lambda** directly from Kinesis Streams for real-time reactions.\n",
    "- For very low-latency, **Kinesis Streams + Lambda** is a common pairing.\n",
    "- For hands-off delivery, go with **Kinesis Firehose**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìé AWS Docs\n",
    "\n",
    "- [Amazon Kinesis Overview](https://aws.amazon.com/kinesis/)\n",
    "- [Amazon Kinesis Firehose](https://docs.aws.amazon.com/firehose/latest/dev/what-is-this-service.html)\n",
    "- [Amazon MSK](https://aws.amazon.com/msk/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
