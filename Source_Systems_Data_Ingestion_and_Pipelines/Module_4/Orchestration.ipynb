{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90efe29a",
   "metadata": {},
   "source": [
    "# Table of Contents \n",
    "\n",
    "- [Cron Jobs (Before Orchestration)](#cron-jobs-before-orchestration)\n",
    "- [Evolution of Orchestration tools](#evolution-of-orchestration-tools)\n",
    "- [Orchestration Basics](#orchestration-basics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7763c68",
   "metadata": {},
   "source": [
    "# Cron Jobs (Before Orchestration)\n",
    "\n",
    "![Cron Logo](./images/cron.png)\n",
    "\n",
    "## What is Cron?\n",
    "**Cron** is a Unix/Linux utility (from the 1970s) that automatically runs commands or scripts on a schedule you define.\n",
    "\n",
    "---\n",
    "\n",
    "## How a Cron Job Works\n",
    "A cron job line has **five timing fields** followed by the command:\n",
    "\n",
    "    MINUTE(0‚Äì59) HOUR(0‚Äì23) DAY(1‚Äì31) MONTH(1‚Äì12) WEEKDAY(0‚Äì6)  command\n",
    "\n",
    "You can use `*` (asterisk) to mean ‚Äúany value‚Äù.\n",
    "\n",
    "**Examples**\n",
    "- Run at midnight on Jan 1 every year:\n",
    "\n",
    "      0 0 1 1 * echo \"Happy New Year\"\n",
    "\n",
    "- Run every night at midnight:\n",
    "\n",
    "      0 0 * * * python ingest_from_rest_api.py\n",
    "\n",
    "![Cron Fields](./images/cron_work.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Before Orchestration: Pure Scheduling with Cron\n",
    "Teams used to chain data pipeline steps by scheduling **multiple cron jobs** a little apart in time so they‚Äôd (hopefully) run in order:\n",
    "\n",
    "- 12:00 AM ‚Üí ingest API  \n",
    "- 01:00 AM ‚Üí transform  \n",
    "- 02:00 AM ‚Üí combine with DB  \n",
    "- 03:00 AM ‚Üí load to warehouse\n",
    "\n",
    "This is a **pure scheduling approach**‚Äîno dependency awareness, just timed starts.\n",
    "\n",
    "---\n",
    "\n",
    "## Problems with Pure Cron Scheduling\n",
    "- ‚ùå No dependency checks (a 1 AM job runs even if the midnight job failed or ran long)  \n",
    "- ‚ùå Minimal monitoring/alerting; failures often discovered late  \n",
    "- ‚ùå Debugging & observability are DIY (logs, alerts, retries)  \n",
    "- ‚ùå Fragile when task durations vary\n",
    "\n",
    "![Pure Scheduling Drawbacks](./images/pure_scheduiling.png)\n",
    "\n",
    "---\n",
    "\n",
    "## When Cron Is Still a Good Fit\n",
    "- ‚úÖ Simple, independent, recurring tasks (backups, log cleanup, small data fetches)  \n",
    "- ‚úÖ Quick prototypes where a full orchestrator is overkill  \n",
    "- ‚úÖ Environments with very light automation needs\n",
    "\n",
    "**Rule of thumb:** If tasks depend on other tasks finishing, or you need retries, backfills, SLAs, or rich monitoring‚Äîuse an **orchestration tool** (e.g., Airflow, Prefect, Dagster). Otherwise, Cron is perfectly fine for small periodic jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45bb4a9",
   "metadata": {},
   "source": [
    "# Evolution of Orchestration Tools\n",
    "\n",
    "Orchestration is the backbone of modern data engineering, ensuring that complex workflows run in sequence, on time, and with reliability. Let‚Äôs walk through its evolution and see how the tooling landscape has shifted over the years.\n",
    "\n",
    "---\n",
    "\n",
    "## üìú Early Days ‚Äì In-House Solutions\n",
    "Before the past decade, orchestration was largely **limited to big tech companies** because:\n",
    "- Open-source or managed orchestration tools didn‚Äôt exist.\n",
    "- Building in-house systems was expensive and complicated.\n",
    "\n",
    "---\n",
    "\n",
    "## üï∞ Timeline of Orchestration Tools\n",
    "\n",
    "![Evolution Timeline](./images/evolution.png)\n",
    "\n",
    "- **Late 2000s**:  \n",
    "  - **Facebook‚Äôs DataSwarm** ‚Üí built internally to manage their growing data workflows.\n",
    "  \n",
    "- **2010s**:  \n",
    "  - **Apache Oozie** ‚Üí became popular, but it was tied to Hadoop clusters, making it less flexible in heterogeneous environments.\n",
    "\n",
    "- **2014**:  \n",
    "  - **Airbnb released Airflow** ‚Üí inspired by earlier tools like DataSwarm but designed to be **open-source, flexible, and Python-based**.  \n",
    "  - Quickly became the *industry standard*.\n",
    "\n",
    "- **2019**:  \n",
    "  - **Apache Airflow** graduated to a full Apache Software Foundation project, solidifying its role as the most widely adopted orchestration framework.\n",
    "\n",
    "---\n",
    "\n",
    "## üåü Airflow: Advantages & Challenges\n",
    "\n",
    "![Airflow Advantages](./images/adv_airflow.png)\n",
    "\n",
    "**Advantages**\n",
    "- Written in **Python**, making it flexible and widely accessible.  \n",
    "- Very **active open-source community** with frequent commits and bug fixes.  \n",
    "- Available as a **managed service** through providers like AWS, GCP, and Astronomer.  \n",
    "\n",
    "**Challenges**\n",
    "- Struggles with **scalability** for very large workflows.  \n",
    "- Limited built-in support for **data integrity**.  \n",
    "- Lacks **native support for streaming pipelines**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÆ Other Open-Source Orchestration Tools\n",
    "\n",
    "![Other Tools](./images/other_orche_tools.png)\n",
    "\n",
    "As the ecosystem evolved, newer tools emerged, aiming to improve on Airflow‚Äôs design while addressing its shortcomings:\n",
    "\n",
    "- **Luigi**: Early workflow management tool.  \n",
    "- **Conductor**: Focused on microservice orchestration.  \n",
    "- **Prefect**: More scalable and developer-friendly orchestration system.  \n",
    "- **Dagster**: Adds built-in data quality testing and transformation features.  \n",
    "- **Mage**: Provides integrated data transformation and monitoring.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Example Improvements\n",
    "\n",
    "![Examples of Other Tools](./images/eg_other_orche.png)\n",
    "\n",
    "- **Prefect** ‚Üí More scalable than Airflow, making it a good fit for heavy workloads.  \n",
    "- **Dagster & Mage** ‚Üí Bring built-in **data quality testing** and transformation features, helping ensure correctness beyond just scheduling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104ef677",
   "metadata": {},
   "source": [
    "# Orchestration Basics\n",
    "\n",
    "## Why Orchestration?\n",
    "Orchestration is about managing complex **data pipelines** more reliably than simple Cron jobs. While Cron can schedule tasks, orchestration tools give you advanced control over dependencies, monitoring, alerts, and fallback plans.\n",
    "\n",
    "**Pros:**\n",
    "- Set up dependencies between tasks  \n",
    "- Monitor task execution  \n",
    "- Get alerts on failures  \n",
    "- Create fallback plans  \n",
    "\n",
    "**Cons:**\n",
    "- Adds more operational overhead compared to simple Cron scheduling  \n",
    "\n",
    "![Pros and Cons](./images/pro_con.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Directed Acyclic Graphs (DAGs)\n",
    "At the heart of orchestration is the **Directed Acyclic Graph (DAG)** ‚Äî a structure where:\n",
    "- Each **task** is a node  \n",
    "- Each **arrow** (edge) shows data flow  \n",
    "- Data flows **only in one direction**  \n",
    "- No loops or cycles are allowed  \n",
    "\n",
    "This ensures predictable execution order.\n",
    "\n",
    "![DAG](./images/dag.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Dependencies Between Tasks\n",
    "With Cron, tasks could overlap or break if one runs late.  \n",
    "With orchestration, you can **define dependencies**: a task won‚Äôt start until its upstream tasks are complete.\n",
    "\n",
    "![Task Dependencies](./images/task_based.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Orchestration in Airflow\n",
    "In Airflow, DAGs are defined in Python. You programmatically specify tasks and how they depend on each other.\n",
    "\n",
    "![Code Example](./images/code_for_orchestration_.png)\n",
    "\n",
    "Airflow then lets you:\n",
    "- Visualize DAGs  \n",
    "- Trigger runs manually or on schedule  \n",
    "- Monitor progress & debug issues  \n",
    "\n",
    "---\n",
    "\n",
    "## Time-based vs Event-based Triggers\n",
    "Airflow DAGs can run on **time-based schedules** (like Cron) or be triggered by **events** (like new data arriving).\n",
    "\n",
    "![Time or Event Based](./images/time_or_event_based.png)\n",
    "\n",
    "### Example: Time-based\n",
    "Run daily at midnight:  \n",
    "![Example Time-based](./images/eg_time_based.png)\n",
    "\n",
    "### Example: Event-based\n",
    "Run when a dataset updates:  \n",
    "![Example Event-based](./images/eg_event_based.png)\n",
    "\n",
    "You can even make **part of a DAG** wait for an external event, e.g., a file landing in S3.  \n",
    "\n",
    "![External Flow](./images/external_flow.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Data Quality Checks\n",
    "Another orchestration benefit: embedding **data quality checks** into the DAG.  \n",
    "For example:\n",
    "- Count of null values  \n",
    "- Validating ranges of values  \n",
    "- Schema verification  \n",
    "\n",
    "![Quality Checks](./images/quality_checks.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "Orchestration tools (like Airflow) provide the structure to:\n",
    "- Define pipelines as **DAGs**  \n",
    "- Manage **dependencies** between tasks  \n",
    "- Run on **time or event conditions**  \n",
    "- Monitor and alert on failures  \n",
    "- Enforce **data quality**  \n",
    "\n",
    "Though more complex than Cron, orchestration is essential for reliable and scalable data engineering workflows."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
