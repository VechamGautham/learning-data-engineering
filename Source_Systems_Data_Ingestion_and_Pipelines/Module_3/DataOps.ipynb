{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc57958",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [Introduction to Dataops](#-introduction-to-dataops)\n",
    "- [DataOps Automation](#dataops-automation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6131db6c",
   "metadata": {},
   "source": [
    "# Introduction to DataOps\n",
    "\n",
    "**DataOps** is a collaborative data management practice focused on improving the communication, integration, and automation of data flows between data managers and data consumers across an organization.  \n",
    "It aims to deliver **faster, more reliable, and higher-quality** data analytics through the adoption of agile development, DevOps practices, and lean manufacturing principles.\n",
    "\n",
    "---\n",
    "\n",
    "## üèõ The Three Pillars of DataOps\n",
    "\n",
    "1. **Automation**  \n",
    "   - Streamlines repetitive processes using tools and scripts.\n",
    "   - Enables rapid, reliable, and scalable data pipeline deployments.\n",
    "   \n",
    "2. **Observability & Monitoring**  \n",
    "   - Ensures full visibility into the performance, health, and data quality across pipelines.\n",
    "   - Uses monitoring tools and alerts to proactively detect issues.\n",
    "   \n",
    "3. **Incident Response**  \n",
    "   - Defines structured processes for identifying, triaging, and resolving data issues quickly.\n",
    "   - Reduces downtime and minimizes business impact.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Pillars Diagram\n",
    "\n",
    "![DataOps Pillars](./images/dataops_pillers.png)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Automation in DataOps\n",
    "\n",
    "Automation is a core pillar of DataOps, enabling teams to reduce manual intervention, minimize human errors, and accelerate delivery.\n",
    "\n",
    "### **Key Automation Practices**\n",
    "1. **Continuous Integration and Continuous Delivery (CI/CD)**  \n",
    "   - Automates the process of building, testing, integrating, and deploying data pipelines.\n",
    "   \n",
    "2. **Infrastructure as Code (IaC)**  \n",
    "   - Uses code to define, provision, and manage infrastructure resources.\n",
    "   - Ensures reproducibility and scalability.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ† Tools for Automation\n",
    "\n",
    "Some popular tools used for automation in DataOps include:\n",
    "\n",
    "- **Terraform** ‚Äì For provisioning and managing infrastructure as code.  \n",
    "- **Ansible** ‚Äì For configuration management and deployment automation.  \n",
    "- **Jenkins / GitHub Actions / GitLab CI** ‚Äì For CI/CD pipeline automation.  \n",
    "- **Apache Airflow / Prefect** ‚Äì For orchestrating data workflows.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Automation Diagram\n",
    "\n",
    "![Automation](./images/automation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eca541",
   "metadata": {},
   "source": [
    "# DataOps Automation\n",
    "\n",
    "## üìå What is DataOps Automation?\n",
    "**DataOps Automation** is the practice of streamlining and automating every stage of a **data pipeline** ‚Äî from ingestion to transformation to delivery ‚Äî in order to:\n",
    "- Reduce manual intervention.\n",
    "- Improve reliability and consistency.\n",
    "- Enable faster and safer deployments.\n",
    "- Integrate best practices from **DevOps** into data engineering workflows.\n",
    "\n",
    "It borrows concepts from **DevOps automation** like:\n",
    "- **CI/CD (Continuous Integration / Continuous Delivery)**\n",
    "- **Version Control**\n",
    "- **Infrastructure as Code (IaC)**\n",
    "- **Orchestration with DAGs** (Directed Acyclic Graphs)\n",
    "\n",
    "---\n",
    "\n",
    "## üõ† Levels of DataOps Automation\n",
    "\n",
    "### 1Ô∏è‚É£ No Automation\n",
    "- All processes are run **manually** by engineers.\n",
    "- Time-consuming, prone to human error, and difficult to scale.\n",
    "\n",
    "![Manual Automation](./images/manul.png)\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Pure Scheduling (Semi-Automation)\n",
    "- Each stage of the pipeline runs on a **fixed schedule**.\n",
    "- Improves consistency, but lacks dynamic triggers and dependency management.\n",
    "\n",
    "![Semi Automation](./images/semi_automatio.png)\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Fully Automated with Orchestration (e.g., Apache Airflow)\n",
    "- Pipelines are defined as a **Directed Acyclic Graph (DAG)**.\n",
    "- Orchestration tools like **Apache Airflow** ensure tasks run in the right order, only when dependencies are met.\n",
    "- Enables retries, error handling, and monitoring.\n",
    "\n",
    "![Fully Automated](./images/fully_autmated_via_apache_airflow.png)\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ CI/CD in DataOps\n",
    "**Continuous Integration / Continuous Delivery** automates:\n",
    "1. **Build** ‚Äì Prepare code and configurations.\n",
    "2. **Test** ‚Äì Automatic review and testing of new code or data transformations.\n",
    "3. **Integrate** ‚Äì Merge tested changes into the main pipeline.\n",
    "4. **Deploy** ‚Äì Automatic delivery into production.\n",
    "\n",
    "This approach ensures rapid, reliable updates to both **code and data**.\n",
    "\n",
    "![CI/CD](./images/ci-cd.png)\n",
    "\n",
    "---\n",
    "\n",
    "## üíª Infrastructure as Code (IaC)\n",
    "- Maintain infrastructure configurations as **code**.\n",
    "- Example: Provisioning cloud storage, compute resources, and databases through code files.\n",
    "- Benefits:\n",
    "  - Version control for infrastructure.\n",
    "  - Reproducibility.\n",
    "  - Easy rollback to previous setups.\n",
    "\n",
    "![Infrastructure as Code](./images/iac.png)\n",
    "\n",
    "---\n",
    "\n",
    "## üìÇ Version Control for Code & Data\n",
    "- Tracks **changes** in both:\n",
    "  - **Pipeline code** (SQL, Python, configs).\n",
    "  - **Data versions** moving through the pipeline.\n",
    "- Enables rollback to **previous versions** in case of errors.\n",
    "\n",
    "![Version Control](./images/version_control.png)\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Why DataOps Automation Matters\n",
    "- **Consistency** ‚Äì Fewer errors and more predictable results.\n",
    "- **Speed** ‚Äì Faster deployments and updates.\n",
    "- **Scalability** ‚Äì Handle large, complex pipelines without bottlenecks.\n",
    "- **Resilience** ‚Äì Automatic error handling, monitoring, and quick rollbacks.\n",
    "\n",
    "In short, DataOps Automation ensures that **data pipelines run like a well-oiled factory line** ‚Äî continuously delivering trusted data products at high speed and with minimal manual effort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c117e",
   "metadata": {},
   "source": [
    "# üèó Infrastructure as Code (IaC)\n",
    "\n",
    "## üìå What is Infrastructure as Code?\n",
    "**Infrastructure as Code (IaC)** is the practice of defining, deploying, and maintaining infrastructure using **code**, rather than manual processes.  \n",
    "With IaC, you can automate the creation of **networking, security, computing, storage**, and other resources required for your cloud-based data pipelines.\n",
    "\n",
    "Benefits include:\n",
    "- **Automation** ‚Äì Reduce manual effort and human error.\n",
    "- **Scalability** ‚Äì Deploy infrastructure for large, complex systems quickly.\n",
    "- **Consistency** ‚Äì Ensure all environments match the desired configuration.\n",
    "- **Version Control** ‚Äì Track changes and roll back when necessary.\n",
    "\n",
    "---\n",
    "\n",
    "## üï∞ History of IaC\n",
    "\n",
    "![History of IaC](./images/iac_history.png)\n",
    "\n",
    "1. **1970s ‚Äì Configuration Management**\n",
    "   - Engineers used scripts (like early **BASH**) to automate configuration of physical machines.\n",
    "   - Primitive automation for repetitive setup tasks.\n",
    "\n",
    "2. **2006 ‚Äì AWS EC2 Launch**\n",
    "   - Cloud computing became widely accessible.\n",
    "   - Developers could **spin up virtual servers on demand**.\n",
    "\n",
    "3. **2010s ‚Äì Modern IaC Tools**\n",
    "   - Tools like **Terraform**, **AWS CloudFormation**, and **Ansible** emerged.\n",
    "   - Enabled full infrastructure provisioning via code files instead of manual configuration.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è How Terraform Works\n",
    "\n",
    "Terraform is a **cloud-agnostic** IaC tool created by **HashiCorp**.  \n",
    "It uses **HCL (HashiCorp Configuration Language)**, a **declarative** language, to define the desired end state of infrastructure.\n",
    "\n",
    "### Example: S3 Bucket Setup in Terraform\n",
    "\n",
    "![Terraform S3 Config](./images/terraform_s3_config.png)\n",
    "\n",
    "**Key points in Terraform syntax:**\n",
    "- `resource` ‚Üí Keyword indicating the type of entity you want to create.\n",
    "- `\"aws_s3_bucket\"` ‚Üí **Resource type** (provider + service).\n",
    "- `\"data_lake\"` ‚Üí **Resource name** (your internal reference).\n",
    "- `{ ... }` ‚Üí **Configuration block** with key-value pairs.\n",
    "\n",
    "---\n",
    "\n",
    "## üñã Example: Creating a VPC and EC2 Instance\n",
    "\n",
    "![VPC & Instance](./images/vpc_instance_iac.png)\n",
    "```hcl\n",
    "#VPC Creation\n",
    "resource \"aws_vpc\" \"main\" {\n",
    "  cidr_block       = \"10.0.0.0/16\"\n",
    "  instance_tenancy = \"default\"\n",
    "\n",
    "  tags = {\n",
    "    Name = \"main\"\n",
    "  }\n",
    "}\n",
    "\n",
    "#EC2 Instance Creation\n",
    "resource \"aws_instance\" \"web\" {\n",
    "  ami           = data.aws_ami.ubuntu.id\n",
    "  instance_type = \"t3.micro\"\n",
    "\n",
    "  tags = {\n",
    "    Name = \"HelloWorld\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "---\n",
    "\n",
    "## üîÑ Terraform Idempotency\n",
    "\n",
    "![Idempotency](./images/idempotent.png)\n",
    "\n",
    "Terraform ensures **idempotency** ‚Äî running the same configuration multiple times **won‚Äôt recreate resources unnecessarily**:\n",
    "- If the resource **does not exist**, Terraform creates it.\n",
    "- If it **exists but differs** from the desired state, Terraform updates it.\n",
    "- If it **matches exactly**, Terraform does nothing.\n",
    "\n",
    "---\n",
    "\n",
    "## üÜö Bash vs Terraform\n",
    "- **Bash scripts** are **imperative** ‚Üí they execute commands in a specific order without checking the existing state.\n",
    "- Running the same Bash provisioning script twice will create **duplicate resources**.\n",
    "- **Terraform** is **declarative** ‚Üí it checks the current state and only makes necessary changes.\n",
    "- This makes Terraform **safe, repeatable, and idempotent**.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
