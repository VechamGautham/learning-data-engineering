{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b1364d",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [Data Warehouse - Overview & Architecture](#data-warehouse--overview--architecture)\n",
    "- [Database vs Data Lkae vs Data Warehouse](#database-vs-data-lake-vs-data-warehouse--comparison-table)\n",
    "- [Cloud Data Warehouse and MPP Architecture](#cloud-data-warehouse--mpp-architecture)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09adf05c",
   "metadata": {},
   "source": [
    "# Data Warehouse â€” Overview & Architecture\n",
    "\n",
    "## ğŸ“Œ Key Characteristics of a Data Warehouse\n",
    "\n",
    "![Data Warehouse](./images/data_warehouse.png)\n",
    "\n",
    "- **Subject-Oriented** ğŸ§   \n",
    "  Organizes and stores data around key business domains such as Customers, Products, Sales, Finance.  \n",
    "  â†’ Data is modeled to support **decision-making**, not transactions.\n",
    "\n",
    "- **Integrated** ğŸ”—  \n",
    "  Combines data from multiple, heterogeneous sources into a **consistent schema**.\n",
    "\n",
    "- **Non-Volatile** ğŸ“„  \n",
    "  Data is **read-only** â€” it cannot be updated or deleted.  \n",
    "  â†’ Preserves snapshots for historical analysis.\n",
    "\n",
    "- **Time-Variant** ğŸ•°  \n",
    "  Stores both **current and historical** data, unlike OLTP systems.  \n",
    "  â†’ Enables trend analysis over time.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§± Data Warehouseâ€“Centric Architecture (ETL Pattern)\n",
    "\n",
    "![Data Warehouse ETL Architecture](./images/data_warehouse-centric_architecture.png)\n",
    "\n",
    "1. **Extract**  \n",
    "   Pull data from various operational sources â€” databases, APIs, files, etc.\n",
    "\n",
    "2. **Transform**  \n",
    "   Clean, standardize, and model the data in a **staging area**.\n",
    "\n",
    "3. **Load**  \n",
    "   Push transformed data into the **Data Warehouse** with a comprehensive schema.\n",
    "\n",
    "4. **Data Marts** ğŸª  \n",
    "   - Department-specific subsets (e.g. Sales, Marketing, Finance).  \n",
    "   - Often follow **simplified or denormalized schemas**.  \n",
    "   - Improve query performance for specific use cases.\n",
    "\n",
    "5. **Analytics & Reports** ğŸ“Š  \n",
    "   BI tools and analysts use the Data Marts & Warehouse for dashboards and decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”„ Change Data Capture (CDC)\n",
    "\n",
    "![Change Data Capture](./images/data_warehouse-centric_archi_cdc.png)\n",
    "\n",
    "- Instead of extracting the **entire dataset** every time,  \n",
    "  **CDC tracks only changes** (inserts, updates, deletes) in the source systems.\n",
    "\n",
    "- Reduces load on production OLTP databases âœ…  \n",
    "- Keeps the Data Warehouse **incrementally in sync** with source systems.  \n",
    "- Commonly implemented using ETL pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "## âš¡ Evolution of Data Warehouse Implementations\n",
    "\n",
    "![Data Warehouse Implementation](./images/data_warehouse_implementations.png)\n",
    "\n",
    "| Era | Architecture | Key Features |\n",
    "|-----|-------------|--------------|\n",
    "| **Early DW** ğŸ§± | Monolithic servers | Limited performance, single big machine |\n",
    "| **MPP DW** âš™ï¸ | Massively Parallel Processing | Distributes queries across multiple nodes, scans data in parallel |\n",
    "| **Modern Cloud DW** â˜ï¸ | Snowflake, BigQuery, Redshift | Separates **compute & storage**, scales elastically, cost-efficient |\n",
    "\n",
    "### âœ¨ Modern Cloud Data Warehouses\n",
    "- **Amazon Redshift**  \n",
    "- **Google BigQuery**  \n",
    "- **Snowflake**\n",
    "\n",
    "âœ… **Key Advantage**:  \n",
    "- Compute and storage are **independent**, allowing cost-effective scaling.  \n",
    "- Ideal for analytical workloads on very large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Recap\n",
    "\n",
    "- OLTP systems are designed for **transactions**, not heavy analytics.  \n",
    "- Data Warehouses were introduced to:\n",
    "  - Consolidate data from multiple sources\n",
    "  - Provide **historical context**\n",
    "  - Enable **analytical queries** efficiently\n",
    "- **ETL pipelines** â†’ clean & load data into a **centralized warehouse**  \n",
    "- **Data Marts** â†’ business functionâ€“specific views for easier analysis  \n",
    "- **CDC** â†’ keeps data up to date without full reloads  \n",
    "- **Modern DW** leverage **cloud + MPP** for scale & performance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc90e8",
   "metadata": {},
   "source": [
    "# Database vs Data Lake vs Data Warehouse â€” Comparison Table\n",
    "\n",
    "| Feature ğŸ§                          | Database (OLTP) ğŸ§¾                          | Data Lake ğŸŒŠ                                      | Data Warehouse ğŸ¢                                                   |\n",
    "|-------------------------------------|---------------------------------------------|--------------------------------------------------|---------------------------------------------------------------------|\n",
    "| **Primary Purpose**                | Handle **day-to-day transactions**         | Store **large volumes of raw / semi-structured data** cheaply | **Analytics, reporting & decision-making**                         |\n",
    "| **Schema**                          | Strict, normalized                         | Flexible or **schema-on-read**                   | Structured, **modeled** (e.g. Star / Snowflake schema)              |\n",
    "| **Data Type**                       | Mostly structured                          | Structured, semi-structured, unstructured        | Structured, cleaned & integrated                                   |\n",
    "| **Data Processing**                | OLTP (row-based inserts/updates)          | Batch or streaming (big data frameworks)        | OLAP (columnar scans, aggregations, joins)                         |\n",
    "| **Storage Layer**                  | Disk + RAM (local)                         | Disk / Object storage (e.g., S3, ADLS, HDFS)     | Disk-based (often columnar format on cloud object storage)         |\n",
    "| **RAM Usage**                      | High â€” for fast concurrent writes & lookups | Low for storage; RAM needed only during Spark/compute jobs | Moderate; used mainly during **query execution**, not for storage |\n",
    "| **Query Patterns**                 | Fast reads/writes on individual records   | Heavy ETL/ELT, ML workloads, large scans        | Analytical queries, aggregations, dashboards                       |\n",
    "| **Performance Optimization**       | Indexes, B-trees, in-memory caching       | Parallel processing, schema-on-read            | Columnar storage, MPP (Massively Parallel Processing), caching     |\n",
    "| **Cost**                            | Expensive to scale for big analytics       | Cheap storage, variable compute cost            | Cost-effective analytics, separates **compute & storage** in modern cloud DWs |\n",
    "| **Data Freshness**                 | Real-time (transactions)                  | Near real-time or batch                        | Batch or near real-time (depending on ETL/CDC setup)               |\n",
    "| **Examples**                        | MySQL, PostgreSQL, Oracle, SQL Server     | S3, ADLS, HDFS, Delta Lake                      | Snowflake, BigQuery, Redshift, Synapse                             |\n",
    "| **Best For**                        | Transactional apps, operational systems   | Data exploration, staging, ML feature stores   | Business intelligence, dashboards, historical analysis             |\n",
    "\n",
    "---\n",
    "\n",
    "## âœ¨ Key Insights\n",
    "\n",
    "- ğŸ§¾ **Databases** are great for **fast, reliable transactions** but are **not optimized for analytical queries** over large datasets.  \n",
    "- ğŸŒŠ **Data Lakes** are great for **raw, large-scale data storage** at low cost, but **query performance depends on the compute engine** (e.g., Spark).  \n",
    "- ğŸ¢ **Data Warehouses** sit in between: they combine structured modeling, columnar storage, and parallel processing to support **high-performance analytics**.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Final One-liner\n",
    "\n",
    "> â€œA **database** is built for transactions, a **data lake** is built for storage, and a **data warehouse** is built for analytics.â€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b4176",
   "metadata": {},
   "source": [
    "# Cloud Data Warehouse & MPP Architecture \n",
    "\n",
    "## ğŸ§  1. MPP Architecture for Amazon Redshift\n",
    "\n",
    "![MPP Architecture](./images/mpp_archi.png)\n",
    "\n",
    "- **Redshift Cluster** = Collection of computing resources.\n",
    "- Consists of:\n",
    "  - ğŸ§  **Leader Node** â†’ Coordinates the cluster, plans queries.\n",
    "  - ğŸ’» **Compute Nodes** â†’ Store data & execute query steps in parallel.\n",
    "- Each compute node is divided into **Slices** ğŸ§©:\n",
    "  - Each slice gets a share of **CPU**, **memory**, and **disk**.\n",
    "  - Data is distributed across slices for parallel processing.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ 2. How MPP Query Execution Works\n",
    "\n",
    "![MPP Execution Steps](./images/mpp_archi_steps.png)\n",
    "\n",
    "1. **Client Application** connects to Redshift using JDBC/ODBC.  \n",
    "2. The **Leader Node**:\n",
    "   - Parses the SQL query.  \n",
    "   - Generates an **execution plan**.  \n",
    "   - Compiles the plan into optimized steps.  \n",
    "3. The **Leader Node distributes code** to slices on compute nodes.  \n",
    "4. Each slice **processes its portion of data** in parallel.  \n",
    "5. Compute nodes return intermediate results to the leader node.  \n",
    "6. The leader node **aggregates the results** and sends the final answer back to the client.\n",
    "\n",
    "ğŸ‘‰ This is what gives Redshift **Massively Parallel Processing (MPP)** power â€” multiple slices work simultaneously.\n",
    "\n",
    "---\n",
    "\n",
    "## âš¡ 3. Scaling Up â€” Adding More Compute Power\n",
    "\n",
    "![Scaling Redshift](./images/more_compute.png)\n",
    "\n",
    "- As data volume or workload increases, you can **scale the cluster** by:\n",
    "  - **Adding more compute nodes** horizontally.\n",
    "  - **Upgrading the node type** vertically (e.g., to more powerful instances).  \n",
    "- This improves:\n",
    "  - **Parallel processing capacity** ğŸ§®  \n",
    "  - **Query performance** ğŸš€  \n",
    "  - **Throughput for concurrent users** ğŸ‘¥\n",
    "\n",
    "âœ¨ One of the biggest advantages of **cloud data warehouses** is that scaling is **elastic** â€” you donâ€™t need to provision huge upfront infrastructure like in traditional on-premises systems.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§­ 5. Data Warehouseâ€“Centric ELT Architecture\n",
    "\n",
    "![Architecture](./images/archi.png)\n",
    "\n",
    "1. **Extract** â†’ Ingest raw data from multiple sources.  \n",
    "2. **Load** â†’ Push raw data directly into the cloud data warehouse.  \n",
    "3. **Transform** â†’ Clean & model data inside the warehouse using its compute power.\n",
    "\n",
    "ğŸ‘‰ Modern cloud DWs (Redshift, BigQuery, Snowflake) make **ELT** faster than traditional ETL because they can handle massive transformations internally.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒ 6. Traditional vs Cloud Data Warehouse\n",
    "\n",
    "![Cloud Data Warehouse Comparison](./images/cloud_Data_warhosu.png)\n",
    "\n",
    "| Feature ğŸ§° | Traditional DW ğŸ§± | Cloud DW â˜ï¸ |\n",
    "|-----------|-------------------|-------------|\n",
    "| **Structure** | Highly structured | Highly structured |\n",
    "| **Modeling** | Data modeled for analytics | Data modeled for analytics |\n",
    "| **Processing Power** | Limited to fixed MPP capacity | **Elastic scaling**, on-demand |\n",
    "| **Storage Format** | Row or columnar | **Columnar + compression** |\n",
    "| **Scaling** | Vertical, expensive | Horizontal + vertical, elastic |\n",
    "| **Cost** | Upfront infra | Pay-as-you-go |\n",
    "| **Use Case** | Fixed infra, on-prem | Modern, scalable analytics |\n",
    "\n",
    "---\n",
    "\n",
    "## âœ¨ 7. Why Cloud Data Warehouses Are Powerful\n",
    "\n",
    "- **Elastic scaling** â†’ Add nodes or upgrade types when needed.  \n",
    "- **Columnar storage** â†’ Efficient analytical queries.  \n",
    "- **Separation of storage & compute** â†’ Cost-performance optimization.  \n",
    "- **MPP** â†’ Parallel query execution for petabyte-scale analytics.  \n",
    "- **Supports ELT** â†’ Load raw data, transform inside warehouse.\n",
    "\n",
    "ğŸ‘‰ Platforms like **Snowflake**, **BigQuery**, and **Redshift** enable organizations to run high-volume analytics with flexibility and speed.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ Summary\n",
    "\n",
    "| Concept | Key Idea |\n",
    "|--------|----------|\n",
    "| **MPP** | Distribute data & processing across nodes for speed. |\n",
    "| **Leader Node** | Coordinates, plans, and aggregates queries. |\n",
    "| **Slices** | Sub-units of compute nodes for parallel processing. |\n",
    "| **Elastic Scaling** | Add/upgrade nodes easily to handle bigger workloads. |\n",
    "| **ELT** | Load first, transform inside DW. |\n",
    "| **Cloud DW** | Scalable, cost-efficient, high-performance analytics engine. |\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
